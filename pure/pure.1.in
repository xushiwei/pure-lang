.TH Pure 1 "February 2009" "Pure" "Pure Manual"
.hw name-space
.hw name-spaces
.SH NAME
pure \- the Pure interpreter
.SH SYNOPSIS
\fBpure\fP [\fIoptions\fP ...] [\fIscript\fP ...] [-- \fIargs\fP ...]
.br
\fBpure\fP [\fIoptions\fP ...] -x \fIscript\fP [\fIargs\fP ...]
.SH OPTIONS
.TP
\fB--help\fP, \fB-h\fP
Print help message and exit.
.TP
.B -i
Force interactive mode (read commands from stdin).
.TP
.BI -I directory
Add a directory to be searched for included source scripts.
.TP
.BI -L directory
Add a directory to be searched for dynamic libraries.
.TP
.B --noediting
Do not use readline for command-line editing.
.TP
\fB--noprelude\fP, \fB-n\fP
Do not load the prelude.
.TP
.B --norc
Do not run the interactive startup files.
.TP
.B -q
Quiet startup (suppresses sign-on message in interactive mode).
.TP
.BR -v [\fIlevel\fP]
Set verbosity level. See below for details.
.TP
.B --version
Print version information and exit.
.TP
.B -x
Execute script with given command line arguments.
.TP
.B --
Stop option processing and pass the remaining command line arguments in the
.B argv
variable.
.SH DESCRIPTION
Pure is a modern-style functional programming language based on term
rewriting. Pure programs are basically collections of equational rules used to
evaluate expressions in a symbolic fashion by reducing them to normal form. A
brief overview of the language can be found in the \fIPURE OVERVIEW\fP section
below. (In case you're wondering, the name ``Pure'' actually refers to the
adjective. But you can also write it as ``PURE'' and take this as a recursive
acronym for the ``Pure Universal Rewriting Engine''.)
.PP
.B pure
is the Pure interpreter. The interpreter has an LLVM backend which
JIT-compiles Pure programs to machine code, hence programs run blazingly fast
and interfacing to C modules is easy, while the interpreter still provides a
convenient, fully interactive environment for running Pure scripts and
evaluating expressions.
.PP
Pure programs (a.k.a.
.IR scripts )
are just ordinary text files containing Pure code. They must be encoded in
UTF-8 (which subsumes 7 bit ASCII), other encodings such as Latin-1 are
.I not
supported. A bunch of syntax highlighting files and programming modes for
various popular text editors are included in the Pure sources. There's no
difference between the Pure programming language and the input language
accepted by the interpreter, except that the interpreter also understands some
special commands when running in interactive mode; see the \fIINTERACTIVE
USAGE\fP section for details.
.PP
If any source scripts are specified on the command line, they are loaded and
executed, after which the interpreter exits. Otherwise the interpreter enters
the interactive read-eval-print loop. You can also use the
.B -i
option to enter the interactive loop (continue reading from stdin) even after
processing some source scripts. To exit the interpreter, just type the
.B quit
command or the end-of-file character (^D on Unix) at the beginning of the
command line.
.PP
Options and source files are processed in the order in which they are given on
the command line. Processing of options and source files ends when either the
.B --
or the
.B -x
option is encountered. The
.B -x
option must be followed by the name of a script to be executed, which becomes
the ``main script'' of the application. In either case, any remaining
parameters are passed to the executing script by means of the global
.B argc
and
.B argv
variables, denoting the number of arguments and the list of the actual
parameter strings, respectively. In the case of
.B -x
this also includes the script name as
.BR argv!0 .
The
.B -x
option is useful, in particular, to turn Pure scripts into executable programs
by including a ``shebang'' like
.sp
.nf
#!/usr/local/bin/pure -x
.fi
.sp
as the first line in your main script. (This trick only works with Unix
shells, though.)
.PP
On startup, the interpreter also defines the
.B version
variable, which is set to the version string of the Pure interpreter, and the
.B sysinfo
variable, which provides a string identifying the host system. These are
useful if parts of your script depend on the particular version of the
interpreter and the system it runs on.
.PP
If available, the prelude script
.B prelude.pure
is loaded by the interpreter prior to any other other definitions, unless the
.B -n
or
.B --noprelude
option is specified. The prelude is searched for in the directory specified
with the
.B PURELIB
environment variable. If the
.B PURELIB
variable is not set, a system-specific default is used. Relative pathnames of
other source scripts specified on the command line are interpreted relative to
the current working directory. In addition, the executed program may load
other scripts and libraries via a
.B using
declaration in the source, which are searched for in a number of locations,
including the directories named with the
.B -I
and
.B -L
options; see the sections \fIDECLARATIONS\fP and \fIC INTERFACE\fP below for
details.
.PP
If the interpreter runs in interactive mode, it may source a few additional
interactive startup files immediately before entering the interactive loop,
unless the
.B --norc
option is specified. First
.B .purerc
in the user's home directory is read, then
.B .purerc
in the current working directory. These are ordinary Pure scripts which can be
used to provide additional definitions for interactive usage. Finally, a
.B .pure
file in the current directory (containing a dump from a previous interactive
session) is loaded if it is present. See the \fIINTERACTIVE USAGE\fP section
for details.
.PP
When the interpreter is in interactive mode and reads from a tty, unless the
.B --noediting
option is specified, commands are read using
.BR readline (3)
(providing completion for all commands listed under \fIINTERACTIVE USAGE\fP,
as well as for symbols defined in the running program). When exiting the
interpreter, the command history is stored in
.BR ~/.pure_history ,
from where it is restored the next time you run the interpreter.
.PP
The
.B -v
option is most useful for debugging the interpreter, or if you are interested
in the code your program gets compiled to. The
.I level
argument is optional; it defaults to 1. Six different levels are implemented
at this time (two more bits are reserved for future extensions). For most
purposes, only the first two levels will be useful for the average Pure
programmer; the remaining levels are most likely to be used by the Pure
interpreter developers.
.TP
.B 1 (0x1)
denotes echoing of parsed definitions and expressions;
.TP
.B 2 (0x2)
adds special annotations concerning local bindings (de Bruijn indices, subterm
paths; this can be helpful to debug tricky variable binding issues);
.TP
.B 4 (0x4)
adds descriptions of the matching automata for the left-hand sides of
equations (you probably want to see this only when working on the guts of the
interpreter).
.TP
.B 8 (0x8)
dumps the ``real'' output code (LLVM assembler, which is as close to the
native machine code for your program as it gets; you \fIdefinitely\fP don't
want to see this unless you have to inspect the generated code for bugs or
performance issues).
.TP
.B 16 (0x10)
adds debugging messages from the
.BR bison (1)
parser; useful for debugging the parser.
.TP
.B 32 (0x20)
adds debugging messages from the
.BR flex (1)
lexer; useful for debugging the lexer.
.PP
These values can be or'ed together, and, for convenience, can be specified in
either decimal or hexadecimal. Thus 0xff always gives you full debugging
output (which isn't most likely be used by anyone but the Pure developers).
.PP
Note that the
.B -v
option is only applied \fIafter\fP the prelude has been loaded. If you want to
debug the prelude, use the
.B -n
option and specify the
.B prelude.pure
file explicitly on the command line. Verbose output is also suppressed for
modules imported through a
.B using
clause. As a remedy, you can use the interactive
.B show
command (see the \fIINTERACTIVE USAGE\fP section below) to list definitions
along with additional debugging information.
.SH PURE OVERVIEW
.PP
Pure is a fairly simple yet powerful language. Programs are basically
collections of rewriting rules and expressions to be evaluated. For
convenience, it is also possible to define global variables and constants, and
for advanced uses Pure offers macro functions as a kind of preprocessing
facility. These are all described below and in the following sections.
.PP
Here's a first example which demonstrates how to define a simple recursive
function in Pure, entered interactively in the interpreter (note that the
``>'' symbol at the beginning of each input line is the interpreter's default
command prompt):
.sp
.nf
> // my first Pure example
> fact 0 = 1;
> fact n::int = n*fact (n-1) \fBif\fP n>0;
> \fBlet\fP x = fact 10; x;
3628800
.fi
.SS Lexical Matters
Pure is a free-format language; whitespace is insignificant, except if it
serves to delimit other symbols. Hence, as shown above, definitions and
expressions at the toplevel have to be terminated with a semicolon, even in
interactive mode.
.PP
Comments have the same syntax as in C++ (using // for line-oriented and
/*\ ...\ */ for multiline comments; the latter may not be nested). Lines
beginning with #! are treated as comments, too; as already discussed above, on
Unix-like systems this allows you to add a ``shebang'' to your main script in
order to turn it into an executable program.
.PP
There are a few reserved keywords which cannot be used as identifiers:
.nf
case const def else end extern if infix infixl infixr let namespace
nullary of otherwise postfix prefix private public then using when with
.fi
.PP
The customary notations for identifiers, numbers and strings are all
provided. In addition, Pure also allows you to define your own operator
symbols. Pure fully supports Unicode, so that you can write your programs in
almost any language and make good use of the special symbols in the Unicode
character set, provided that you encode your scripts in UTF-8. To keep this
simple, besides the ASCII punctuation characters, Pure also considers the
following code points in the Unicode repertoire as punctuation: U+00A1 through
U+00BF, U+00D7, U+00F7, and U+20D0 through through U+2BFF. This comprises the
special symbols in the Latin-1 repertoire, as well as the Combining
Diacritical Marks for Symbols, Letterlike Symbols, Number Forms, Arrows,
Mathematical Symbols, Miscellaneous Technical Symbols, Control Pictures, OCR,
Enclosed Alphanumerics, Box Drawing, Blocks, Geometric Shapes, Miscellaneous
Symbols, Dingbats, Miscellaneous Mathematical Symbols A, Supplemental Arrows
A, Supplemental Arrows B, Miscellaneous Mathematical Symbols B, Supplemental
Mathematical Operators, and Miscellaneous Symbols and Arrows. This should
cover almost everything you'd ever want to use in an operator symbol. All
other extended Unicode characters are effectively treated as ``letters'' which
can be used as identifier constituents.
.SS Definitions and Expression Evaluation
On the surface, Pure is quite similar to other modern functional languages
like Haskell and ML. But under the hood it is a much more dynamic language,
more akin to Lisp. In particular, Pure is dynamically typed, so functions can
be fully polymorphic and you can add to the definition of an existing function
at any time. For instance, we can extend the example above to make the fact
function work with floating point numbers, too:
.sp
.nf
> fact 1.0 = 1.0;
> fact n::double = n*fact (n-1) \fBif\fP n>1;
> fact 10.0;
3628800.0
> fact 10;
3628800
.fi
.PP
Like in Haskell and ML, functions are often defined by
.IR pattern-matching ,
i.e., the left-hand side of a definition is compared to the target expression,
binding the variables in the pattern to their actual values accordingly:
.sp
.nf
> foo (bar x) = x-1;
> foo (bar 99);
98
.fi
.PP
There are no declarations or lexical conventions to distinguish the variables
in an equation. Instead, Pure parses the left-hand side of an equation using
the following syntactic convention, which is also called the
.I head = function
rule: A symbol is a literal function (or constructor) symbol if it is the head
symbol of a function application (like `foo' and `bar' in the above
example). Other identifiers on the left-hand side are the variables of the
equation (like `x' in this example).
.PP
Due to its term rewriting semantics, Pure goes beyond most other functional
languages in that it can do symbolic evaluations just as well as ``normal''
computations:
.sp
.nf
> square x = x*x;
> square 4;
16
> square (a+b);
(a+b)*(a+b)
.fi
.PP
Leaving aside the built-in support for some common data structures such as
numbers and strings, all the Pure interpreter really does is evaluating
expressions in a symbolic fashion, rewriting expressions using the equations
supplied by the programmer, until no more equations are applicable. The result
of this process is called a
.I "normal form"
which represents the ``value'' of the original expression. Keeping with the
tradition of term rewriting, there's no distinction between ``defined'' and
``constructor'' function symbols in Pure; any function symbol (or operator)
also acts as a constructor if it happens to occur in a normal form term:
.sp
.nf
> (x+y)*z = x*z+y*z; x*(y+z) = x*y+x*z;
> x*(y*z) = (x*y)*z; x+(y+z) = (x+y)+z;
> square (a+b);
a*a+a*b+b*a+b*b
.fi
.PP
Expressions are generally evaluated from left to right, innermost expressions
first, i.e., using
.I "call by value"
semantics. Pure also has a few built-in special forms (most notably,
conditional expressions, the short-circuit logical connectives && and ||, the
sequencing operator $$, the lazy evaluation operator &, and the `quote') which
take some or all of their arguments unevaluated, using
.IR "call by name" .
(User-defined special forms can be created with macros. More about that
later.)
.SS Expression Syntax
The Pure language provides built-in support for machine integers (32 bit),
bigints (implemented using GMP), floating point values (double precision
IEEE), character strings (UTF-8 encoded) and generic C pointers (these don't
have a syntactic representation in Pure, though, so they need to be created
with external C functions). Truth values are encoded as machine integers (as
you might expect, zero denotes
.B false
and any non-zero value
.BR true ).
Pure also provides some built-in support for lists and matrices, although most
of the corresponding operations are actually defined in the prelude.
.PP
Expressions consist of the following elements:
.TP
\fBConstants:\fP 4711, 4711L, 1.2e-3, \(dqHello,\ world!\en\(dq
The usual C'ish notations for integers (decimal: 1000, hexadecimal: 0x3e8,
octal: 01750), floating point values and double-quoted strings are all
provided, although the Pure syntax differs in some minor ways, as discussed in
the following. First, there is a special notation for denoting
bigints. Integer constants that are too large to fit into machine integers are
promoted to bigints automatically. Moreover, integer literals immediately
followed by the uppercase letter ``L'' are always interpreted as bigint
constants, even if they fit into machine integers. This notation is also used
when printing bigint constants.
.sp
Second, character escapes in Pure strings have a more flexible syntax borrowed
from the author's Q language, which provides notations to specify any Unicode
character. In particular, the notation
.BR \e\fIn\fP ,
where \fIn\fP is an integer literal written in decimal (no prefix),
hexadecimal (`0x' prefix) or octal (`0' prefix) notation, denotes the Unicode
character (code point) #\fIn\fP. Since these escapes may consist of a varying
number of digits, parentheses may be used for disambiguation purposes; thus,
e.g.
.B \(dq\e(123)4\(dq
denotes character #123 followed by the character `4'. The usual C-like escapes
for special non-printable characters such as
.B \en
are also supported. Moreover, you can use symbolic character escapes of the
form
.BR \e&\fIname\fP; ,
where \fIname\fP is any of the XML single character entity names specified in
the ``XML Entity definitions for Characters'', see
.IR http://www.w3.org/TR/xml-entity-names/ .
Thus, e.g., \(dq\e&copy;\(dq denotes the copyright character (code point
0x000A9).
.TP
\fBFunction and variable symbols:\fP foo, foo_bar, BAR, foo::bar
These consist of the usual sequence of letters (including the underscore) and
digits, starting with a letter. Case is significant, thus foo, Foo and FOO are
distinct identifiers. The `_' symbol, when occurring on the left-hand side of
an equation, is special; it denotes the
.I anonymous variable
which matches any value without actually binding a variable. Identifiers can also be prefixed with a
.I namespace
identifier, like in foo::bar. (This requires that the given namespace has
already been created, as explained under \fINamespaces\fP in the
\fIDECLARATIONS\fP section.)
.TP
\fBOperator and nullary symbols:\fP x+y, x==y, \fBnot\fP\ x
For convenience, Pure also provides you with a limited means to extend the
syntax of the language with your own operators and ``nullary'' (constant)
symbols. These special symbols may take the form of an identifier or a
sequence of punctuation characters. Operators are declared using the
corresponding \fBprefix\fP, \fBpostfix\fP and \fBinfix\fP declarations, which
are discussed in section \fIDECLARATIONS\fP. Operators are just syntax;
enclosing an operator in parentheses, such as (+) or (\fBnot\fP), turns it
into an ordinary function symbol.
.sp
In addition, a symbol declared as \fBnullary\fP denotes an ``operator without
operands'', i.e., a constant symbol. In difference to operators, these are
actually treated more or less like ordinary identifiers, but the
.B nullary
attribute tells the compiler that, when such a symbol occurs on the left-hand
side of an equation, it is to be interpreted as a constant rather than a
variable (cf. the ``head = function'' rule described under \fIDefinitions and
Expression Evaluation\fP above).
.TP
\fBLists and tuples:\fP [x,y,z], x..y, x:xs, x,y,z
The necessary constructors to build lists and tuples are actually defined in
the prelude: `[]' and `()' are the empty list and tuple, `:' produces list
``conses'', and `,' produces ``pairs''. As indicated, Pure provides the usual
syntactic sugar for list values in brackets, such as [x,y,z], which is exactly
the same as x:y:z:[]. Moreover, the prelude also provides an infix `..' 
operator to denote arithmetic sequences such as 1..10. Sequences with
arbitrary stepsizes can be written by denoting the first two sequence
elements using the `:' operator, as in 1.0:1.2..3.0.
.sp
Pure's tuples are a bit unusual: They are constructed by just ``pairing''
things using the `,' operator, for which the empty tuple acts as a neutral
element (i.e., (),x is just x, as is x,()). Pairs always associate to the
right, meaning that x,y,z == x,(y,z) == (x,y),z, where x,(y,z) is the
normalized representation. This implies that tuples are always flat, i.e.,
there are no nested tuples (tuples of tuples); if you need such constructs
then you should use lists instead. Also note that parentheses are generally
only used to group expressions and are \fInot\fP part of the tuple syntax in
Pure. There's one exception to this rule, however, namely that in order to
include a tuple in a bracketed list you have to put it inside
parentheses. E.g., [(1,2),3,(4,5)] is a three element list consisting of the
tuple 1,2, the integer 3, and another tuple 4,5. Likewise, [(1,2,3)] is list
with a single element, the tuple 1,2,3.
.TP
\fBMatrices:\fP {1.0,2.0,3.0}, {1,2;3,4}, {1L,y+1;foo,bar}
Pure also offers matrices, a kind of arrays, as a built-in data structure
which provides efficient storage and element access. These work more or less
like their Octave/MATLAB equivalents, but using curly braces instead of
brackets. As indicated, commas are used to separate the columns of a matrix,
semicolons for its rows. In fact, the {...} construct is rather general,
allowing you to construct new matrices from individual elements and/or
submatrices, provided that all dimensions match up. E.g., {{1;3},{2;4}} is
another way to write a 2x2 matrix in ``column-major'' form (however,
internally all matrices are stored in C's row-major format).
.sp
If the interpreter was built with support for the GNU Scientific Library (GSL)
then both numeric and symbolic matrices are available. The former are thin
wrappers around GSL's homogeneous arrays of double, complex double or
(machine) int matrices, while the latter can contain any mixture of Pure
expressions. Pure will pick the appropriate type for the data at hand. If a
matrix contains values of different types, or Pure values which cannot be
stored in a numeric matrix, then a symbolic matrix is created instead (this
also includes the case of bigints, which are considered as symbolic values as
far as matrix construction is concerned). If the interpreter was built without
GSL support then symbolic matrices are the only kind of matrices supported by
the interpreter.
.sp
More information about matrices and corresponding examples can be found in the
\fIEXAMPLES\fP section below.
.TP
\fBComprehensions:\fP [x,y | x=1..n; y=1..m; x<y], {i~=j | i=1..n; j=1..m}
Pure provides the usual comprehension syntax as a convenient means to
construct both list and matrix values from a ``template'' expression and one
or more ``generator'' and ``filter'' clauses (the former bind a pattern to
values drawn from a list or matrix, the latter are just predicates determining
which generated elements should actually be added to the result). Both list
and matrix comprehensions are in fact syntactic sugar for a combination of
nested lambdas, conditional expressions and ``catmaps'' (a collection of
operations which combine list or matrix construction and mapping a function
over a list or matrix, defined in the prelude), but they are often much easier
to write.
.sp
Matrix comprehensions work pretty much like list comprehensions, but produce
matrices instead of lists. Generator clauses in matrix comprehensions
alternate between row and column generation so that most common mathematical
abbreviations carry over quite easily. Examples of both kinds of
comprehensions can be found in the \fIEXAMPLES\fP section below.
.TP
\fBFunction applications:\fP foo x y z
As in other modern FPLs, these are written simply as juxtaposition (i.e., in
``curried'' form) and associate to the left. Operator applications are written
using prefix, postfix or infix notation, as the declaration of the operator
demands, but are just ordinary function applications in disguise. E.g., x+y is
exactly the same as (+) x y.
.TP
\fBConditional expressions:\fP \fBif\fP x \fBthen\fP y \fBelse\fP z
Evaluates to y or z depending on whether x is ``true'' (i.e., a nonzero
integer). An exception is generated if the condition is not an
integer.
.TP
\fBLambdas:\fP \ex\ ->\ y
These work pretty much like in Haskell. More than one variable may be bound
(e.g, \ex\ y\ ->\ x*y), which is equivalent to a nested lambda
(\ex\ ->\ \ey\ ->\ x*y). Pure also fully supports pattern-matching lambda
abstractions which match a pattern against the lambda argument and bind
multiple lambda variables in one go, such as \e(x,y)\ ->\ x*y.
.TP
\fBCase expressions:\fP \fBcase\fP x \fBof\fP \fIrule\fP; ... \fBend\fP
Matches an expression, discriminating over a number of different cases,
similar to the Haskell \fBcase\fP construct. The expression x is matched in
turn against each left-hand side pattern in the rule list, and the first
pattern which matches x gives the value of the entire expression, by
evaluating the corresponding right-hand side with the variables in the pattern
bound to their corresponding values.
.TP
\fBWhen expressions:\fP x \fBwhen\fP \fIrule\fR; ... \fBend\fP
An alternative way to bind local variables by matching a collection of subject
terms against corresponding patterns. Similar to Aardappel's \fBwhen\fP
construct. A single binding such as x \fBwhen\fP u = v \fBend\fP is equivalent
to \fBcase\fP v \fBof\fP u = x \fBend\fP, but the former is often more
convenient to write. In difference to Aardappel, Pure also allows multiple
definitions in a single \fBwhen\fP clause, which are processed from left to
right, so that later definitions may refer to the variables in earlier
ones. In fact, a \fBwhen\fP expression with multiple definitions is treated
like several nested \fBwhen\fP expressions, with the first binding being the
``outermost'' one.
.TP
\fBWith expressions:\fP x \fBwith\fP \fIrule\fR; ... \fBend\fP
Defines local functions. Like Haskell's \fBwhere\fP construct, but it can be
used anywhere inside an expression (just like Aardappel's \fBwhere\fP, but
Pure uses the keyword \fBwith\fP which better lines up with \fBcase\fP and
\fBwhen\fP). Several functions can be defined in a single \fBwith\fP clause,
and the definitions may consist of as many equations as you want.
.SS Operators and Precedence
Expressions are parsed according to the following precedence rules: Lambda
binds most weakly, followed by
.BR when ,
.B with
and
.BR case ,
followed by conditional expressions (\fBif\fP-\fBthen\fP-\fBelse\fP), followed
by the
.IR "simple expressions" ,
i.e., all other kinds of expressions involving operators, function
applications, constants, symbols and other primary expressions. Precedence and
associativity of operator symbols are given by their declarations (in the
prelude or the user's program), and function application binds stronger than
all operators. Parentheses can be used to override default precedences and
associativities as usual.
.PP
The common operator symbols like +, -, *, / etc. are all declared at the
beginning of the prelude, see the
.B prelude.pure
script for a list of these. Arithmetic and relational operators mostly follow
C conventions. However, out of necessity (\fB!\fP, \fB&\fP and \fB|\fP are
used for other purposes in Pure) the logical and bitwise operations, as well
as the negated equality predicates are named a bit differently:
.BR ~ ,
.B &&
and
.B ||
denote logical negation, conjunction and disjunction, while the corresponding
bitwise operations are named
.BR not ,
.B and
and
.BR or ,
and, following these conventions, inequality is denoted
.BR ~= .
Also note that && and || are special forms which are evaluated in
short-circuit mode like in C (see below), whereas the bitwise connectives
receive their arguments using call-by-value, just like the other arithmetic
operations.
.SS Special Forms
As already mentioned, some operations are actually implemented as special
forms. In particular, the conditional expression \fBif\fP x \fBthen\fP y
\fBelse\fP z is a special form with call-by-name arguments y and z; only one
of the branches is actually evaluated, depending on the value of x. Similarly,
the logical connectives && and || evaluate their operands in
.I short-circuit
mode just like in C. Thus, e.g., x&&y immediately becomes false if x evaluates
to false, without ever evaluating y. Also note that && and ||
.I only
work with machine int arguments and always raise an exception in case of
argument mismatch, so they cannot be used for symbolic evaluations unless you
explicitly ``quote'' them using the
.B quote
primitive discussed below. In contrast, the bitwise connectives (not, and, or)
use the standard call-by-value argument passing, and the prelude defines these
operations only for machine int and bigint operands, so that they can be used
in symbolic expressions like `a and b or c'.
.PP
The
.I sequencing
operator $$ evaluates its left operand, immediately throws the result away and
then goes on to evaluate the right operand which gives the result of the
entire expression. This operator is useful to write imperative-style code such
as the following prompt/input interaction:
.sp
.nf
> \fBusing\fP system;
> puts "Enter a number:" $$ scanf "%g";
Enter a number:
21
21.0
.fi
.PP
We mention in passing here that the same effect can be achieved with a
.B when
clause, which also allows you to execute a function solely for its
side-effects and just ignore the return value:
.sp
.nf
> scanf "%g" \fBwhen\fP puts "Enter a number:" \fBend\fP;
Enter a number:
21
21.0
.fi
.PP
The & operator does
.IR "lazy evaluation" .
This is the only postfix operator defined in the standard prelude, written as
`x&', where x is an arbitrary Pure expression. The & operator binds stronger
than any other operation except function application. It turns its operand
into a kind of parameterless anonymous closure, deferring its
evaluation. These kinds of objects are also commonly known as
.I thunks
or
.IR futures .
When the value of a future is actually needed (during pattern-matching, or
when the value becomes an argument of a C call), it is evaluated automagically
and gets
.IR memoized ,
i.e., the computed result replaces the thunk so that it only has to be
computed once. Futures are useful to implement all kinds of lazy data
structures in Pure, in particular: lazy lists a.k.a.
.IR streams .
A stream is simply a list with a thunked tail, which allows it to be
infinite. The Pure prelude defines many functions for creating and
manipulating these kinds of objects; further details and examples can be found
in the \fIEXAMPLES\fP section below.
.PP
Last but not least, the special form
.B quote
quotes an expression, i.e., `quote x' returns just x itself \fIwithout\fP
evaluating it. The runtime provides a function
.B eval
which can be used to evaluate the quoted expression at a later time. For
instance:
.sp
.nf
> \fBlet\fP x = quote (2*42+2^12); x;
2*42+2^12
> eval x;
4180.0
.fi
.PP
This facility should be well familiar to Lisp programmers. Note that only
simple expressions can be quoted in Pure, special constructs such as
conditionals and local bindings will be evaluated as usual. This allows you to
forcibly evaluate parts of a quoted expression, as in the following example:
.sp
.nf
> quote (2*42+(2^n \fBwhen\fP n = 2*6 \fBend\fP));
2*42+4096.0
.fi
.PP
In addition, a Lisp-like ``quasiquote'' is provided in the prelude; see the
\fIMACROS\fP section for details.
.SS Toplevel
At the toplevel, a Pure program basically consists of rewriting rules (which
are used to define functions and macros), constant and variable definitions,
and expressions to be evaluated:
.TP
\fBRules:\fP \fIlhs\fP = \fIrhs\fP;
Rewriting rules always combine a left-hand side
.I pattern
(which must be a simple expression) and a right-hand side (which can be any
kind of Pure expression described above). The same format is also used in
.BR with ,
.B when
and
.B case
expressions. In toplevel rules,
.B with
and
.B case
expressions, this basic form can also be augmented with a condition
\fBif\fP\ \fIguard\fP
tacked on to the end of the rule, where \fIguard\fP is an integer expression
which determines whether the rule is applicable. Moreover, the keyword
.B otherwise
may be used to denote an empty guard which is always true (this is syntactic
sugar to point out the ``default'' case of a definition; the interpreter just
treats this as a comment). Pure also provides some abbreviations for factoring
out common left-hand or right-hand sides in collections of rules; see section
\fIRULE SYNTAX\fP below for details.
.TP
\fBMacro rules:\fP \fBdef\fP \fIlhs\fP = \fIrhs\fP;
A rule starting with the keyword
.B def
defines a
.I macro
function. No guards or multiple left-hand and right-hand sides are permitted
here. Macro rules are used to preprocess expressions on the right-hand side of
other definitions at compile time, and are typically employed to implement
user-defined special forms and simple kinds of optimization rules. See the
\fIMACROS\fP section below for details and examples.
.TP
\fBGlobal variable bindings:\fP \fBlet\fP \fIlhs\fP = \fIrhs\fP;
Binds every variable in the left-hand side pattern to the corresponding
subterm of the right-hand side (after evaluating it). This works like a
\fBwhen\fP clause, but serves to bind \fIglobal\fP variables occurring free on
the right-hand side of other function and variable definitions.
.TP
\fBConstant bindings:\fP \fBconst\fP \fIlhs\fP = \fIrhs\fP;
An alternative form of \fBlet\fP which defines constants rather than
variables. (These are not to be confused with
.B nullary
symbols which simply stand for themselves!) Like \fBlet\fP, this construct
binds the variable symbols on the left-hand side to the corresponding values
on the right-hand side (after evaluation). The difference is that
.B const
symbols can only be defined once, after which their values are substituted
directly into the right-hand sides of other definitions, rather than being
looked up at runtime.
.TP
\fBToplevel expressions:\fP \fIexpr\fP;
A singleton expression at the toplevel, terminated with a semicolon, simply
causes the given value to be evaluated (and the result to be printed, when
running in interactive mode).
.SS Scoping Rules
A few remarks about the scope of identifiers and other symbols are in order
here. Like most modern functional languages, Pure uses
.I lexical
or
.I static
binding for local functions and variables. What this means is that the binding
of a local name is completely determined at compile time by the surrounding
program text, and does not change as the program is being executed. In
particular, if a function returns another (anonymous or local) function, the
returned function captures the environment it was created in, i.e., it becomes
a (lexical)
.IR closure .
For instance, the following function, when invoked with a single argument x,
returns another function which adds x to its argument:
.sp
.nf
> foo x = bar \fBwith\fP bar y = x+y \fBend\fP;
> \fBlet\fP f = foo 99; f;
bar
> f 10, f 20;
109,119
.fi
.PP
This works the same no matter what other bindings of `x' may be in effect when
the closure is invoked:
.sp
.nf
> \fBlet\fP x = 77; f 10, (f 20 \fBwhen\fP x = 88 \fBend\fP);
109,119
.fi
.PP
Global bindings of variable and function symbols work a bit differently,
though. Like many languages which are to be used interactively, Pure binds
global symbols
.IR dynamically ,
so that the bindings can be changed easily at any time during an interactive
session. This is mainly a convenience for interactive usage, but works the
same no matter whether the source code is entered interactively or being read
from a script, in order to ensure consistent behaviour between interactive and
batch mode operation.
.PP
So, for instance, you can easily bind a global variable to a new value by just
entering a corresponding
.B let
command:
.sp
.nf
> foo x = c*x;
> foo 99;
c*99
> \fBlet\fP c = 2; foo 99;
198
> \fBlet\fP c = 3; foo 99;
297
.fi
.PP
This works pretty much like global variables in imperative languages, but note
that in Pure the value of a global variable can \fIonly\fP be changed with a
.B let
command at the toplevel. Thus referential transparency is unimpaired; while
the value of a global variable may change between different toplevel
expressions, it will always take the same value in a single evaluation.
.PP
Similarly, you can also add new equations to an existing function at any time:
.sp
.nf
> fact 0 = 1;
> fact n::int = n*fact (n-1) \fBif\fP n>0;
> fact 10;
3628800
> fact 10.0;
fact 10.0
> fact 1.0 = 1.0;
> fact n::double = n*fact (n-1) \fBif\fP n>1;
> fact 10.0;
3628800.0
> fact 10;
3628800
.fi
.PP
(In interactive mode, it is even possible to completely erase a definition,
see section \fIINTERACTIVE USAGE\fP for details.)
.PP
So, while the meaning of a local symbol never changes once its definition has
been processed, toplevel definitions may well evolve while the program is
being processed, and the interpreter will always use the
.I latest
definitions at a given point in the source when an expression is
evaluated. This means that, even in a script file, you have to define all
symbols needed in an evaluation
.I before
entering the expression to be evaluated.
.SH RULE SYNTAX
Basically, the same rule syntax is used in all kinds of global and local
definitions. However, some constructs (specifically, \fBwhen\fP, \fBlet\fP,
\fBconst\fP and \fBdef\fP) use a restricted rule syntax where no guards or
multiple left-hand and right-hand sides are permitted. When matching against a
function or macro call, or the subject term in a \fBcase\fP expression, the
rules are always considered in the order in which they are written, and the
first matching rule (whose guard evaluates to a nonzero value, if applicable)
is picked. (Again, the \fBwhen\fP construct is treated differently, because
each rule is actually a separate definition.)
.PP
In any case, the left-hand side pattern (which, as already mentioned, is
always a simple expression) must not contain repeated variables (i.e., rules
must be ``left-linear''), except for the anonymous variable `_' which matches
an arbitrary value without binding a variable symbol.
.PP
A left-hand side variable (including the anonymous variable) may be followed
by one of the special type tags \fB::int\fP, \fB::bigint\fP, \fB::double\fP,
\fB::string\fP, \fB::matrix\fP, \fB::pointer\fP, to indicate that it can only
match a constant value of the corresponding built-in type. (This is useful if
you want to write rules matching \fIany\fP object of one of these types; note
that there is no way to write out all ``constructors'' for the built-in types,
as there are infinitely many.)
.PP
Pure also supports Haskell-style ``as'' patterns of the form
.IB variable @ pattern
which binds the given variable to the expression matched by the subpattern
.I pattern
(in addition to the variables bound by
.I pattern
itself). This is convenient if the value matched by the subpattern is to be
used on the right-hand side of an equation. Syntactically, ``as'' patterns are
primary expressions; if the subpattern is not a primary expression, it must be
parenthesized. For instance, the following function duplicates the head
element of a list:
.sp
.nf
foo xs@(x:_) = x:xs;
.fi
.PP
The left-hand side of a rule can be omitted if it is the same as for the
previous rule. This provides a convenient means to write out a collection of
equations for the same left-hand side which discriminates over different
conditions:
.sp
.nf
\fIlhs\fR       = \fIrhs\fP \fBif\fP \fIguard\fP;
          = \fIrhs\fP \fBif\fP \fIguard\fP;
          ...
          = \fIrhs\fP \fBotherwise\fP;
.fi
.PP
For instance:
.sp
.nf
fact n  = n*fact (n-1) \fBif\fP n>0;
        = 1 \fBotherwise\fP;
.fi
.PP
Pure also allows a collection of rules with different left-hand sides but the
same right-hand side(s) to be abbreviated as follows:
.sp
.nf
\fIlhs\fP       |
          ...
\fIlhs\fP       = \fIrhs\fP;
.fi
.PP
This is useful if you need different specializations of the same rule which
use different type tags on the left-hand side variables. For instance:
.sp
.nf
fact n::int    |
fact n::double |
fact n         = n*fact(n-1) \fBif\fP n>0;
               = 1 \fBotherwise\fP;
.fi
.PP
In fact, the left-hand sides don't have to be related at all, so that you can
also write something like:
.sp
.nf
foo x | bar y = x*y;
.fi
.PP
However, this is most useful when using an ``as'' pattern to bind a common
variable to a parameter value
.I after
checking that it matches one of several possible argument patterns (which is
slightly more efficient than using an equivalent type-checking guard). E.g.,
the following definition binds the xs variable to the parameter of foo, if it
is either the empty list or a list starting with an integer:
.sp
.nf
foo xs@[] | foo xs@(_::int:_) = ... xs ...;
.fi
.PP
The same construct also works in
.B case
expressions, which is convenient if different cases should be mapped to the
same value, e.g.:
.sp
.nf
\fBcase\fP ans \fBof\fP "y" | "Y" = 1; _ = 0; \fBend\fP;
.fi
.PP
Sometimes it is useful if local definitions (\fBwhen\fP and \fBwith\fP) can be
shared by the right-hand side and the guard of a rule in a function definition
or a \fBcase\fP expression. This can be done by placing the local definitions
behind the guard, as follows (we only show the case of a single \fBwhen\fP
clause here, but of course there may be any number of \fBwhen\fP and
\fBwith\fP clauses behind the guard):
.sp
.nf
\fIlhs\fP = \fIrhs\fP \fBif\fP \fIguard\fP \fBwhen\fP \fIdefns\fP \fBend\fP;
.fi
.PP
Note that this is different from the following, which indicates that the
definitions only apply to the guard but not the right-hand side of the rule:
.sp
.nf
\fIlhs\fP = \fIrhs\fP \fBif\fP (\fIguard\fP \fBwhen\fP \fIdefns\fP \fBend\fP);
.fi
.PP
Conversely, definitions placed \fIbefore\fP the guard only apply to the
right-hand side but not the guard (no parentheses are required in this case):
.sp
.nf
\fIlhs\fP = \fIrhs\fP \fBwhen\fP \fIdefns\fP \fBend\fP \fBif\fP \fIguard\fP;
.fi
.PP
An example showing the use of a local variable binding spanning both the
right-hand side and the guard of a rule is the following quadratic equation
solver, which returns the (real) solutions of the equation x^2+p*x+q=0 if the
discriminant d = p^2/4-q is nonnegative:
.sp
.nf
> \fBusing\fP math;
> solve p q = -p/2+sqrt d,-p/2-sqrt d \fBif\fP d>=0 \fBwhen\fP d = p^2/4-q \fBend\fP;
> solve 4 2; solve 2 4;
-0.585786437626905,-3.41421356237309
solve 2 4
.fi
.PP
Note that the above definition leaves the case of a negative discriminant
undefined.
.PP
As already mentioned, \fBwhen\fP, \fBlet\fP, \fBconst\fP and \fBdef\fP use a
simplified kind of rule syntax which just consists of a left-hand and a
right-hand side separated by `='. Guards or multiple left-hand or right-hand
sides are not permitted in these rules. However, it is possible to omit the
left-hand side if it is just the anonymous variable `_' by itself, indicating
that you don't care about the result. (Note that this doesn't make sense for
\fBdef\fP, you'll get an error in this case.) The right-hand side is still
evaluated, if only for its side-effects, which is handy, e.g., for adding
debugging statements to your code. For instance, here is a variation of the
quadratic equation solver which also prints the discriminant after it has been
computed:
.sp
.nf
> \fBusing\fP math, system;
> solve p q = -p/2+sqrt d,-p/2-sqrt d \fBif\fP d>=0
> \fBwhen\fP d = p^2/4-q; printf "The discriminant is: %g\en" d; \fBend\fP;
> solve 4 2;
The discriminant is: 2
-0.585786437626905,-3.41421356237309
> solve 2 4;
The discriminant is: -3
solve 2 4
.fi
.SH EXAMPLES
Here are a few examples of simple Pure programs.
.PP
The factorial:
.sp
.nf
fact n  = n*fact (n-1) \fBif\fP n>0;
        = 1 \fBotherwise\fP;

\fBlet\fP facts = map fact (1..10); facts;
.fi
.PP
The Fibonacci numbers:
.sp
.nf
fib n   = a  \fBwhen\fP a, b   = fibs n \fBend\fP
             \fBwith\fP fibs n = 0, 1 \fBif\fP n<=0;
                         = \fBcase\fP fibs (n-1) \fBof\fP
                             a, b = b, a+b;
                           \fBend\fP;
             \fBend\fP;

\fBlet\fP fibs = map fib (1..30); fibs;
.fi
.PP
It is worth noting here that in most cases Pure performs tail call
optimization so that tail-recursive definitions like the following will be
executed in constant stack space (see the \fICAVEATS AND NOTES\fP section for
more details on this).
.sp
.nf
// tail-recursive factorial using an "accumulating parameter"
fact n = loop 1 n \fBwith\fP
  loop p n = \fBif\fP n>0 \fBthen\fP loop (p*n) (n-1) \fBelse\fP p;
\fBend\fP;
.fi
.PP
Here is an example showing how constants are defined and used. Constant
definitions take pretty much the same form as variable definitions with
.B let
(see above), but work more like the definition of a parameterless function
whose value is precomputed at compile time:
.sp
.nf
> \fBextern\fP double atan(double);
> \fBconst\fP pi = 4*atan 1.0;
> pi;
3.14159265358979
> foo x = 2*pi*x;
> \fBshow\fP foo
foo x = 2*3.14159265358979*x;
> foo 1;
6.28318530717958
.fi
.SS List Comprehensions
List comprehensions are Pure's main workhorse for generating and processing
all kinds of list values. Here's a well-known example, Erathosthenes'
classical prime sieve:
.sp
.nf
primes n        = sieve (2..n) \fBwith\fP
  sieve []      = [];
  sieve (p:qs)  = p : sieve [q | q = qs; q mod p];
\fBend\fP;
.fi
.sp
For instance:
.sp
.nf
> primes 100;
[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97]
.fi
.PP
If you dare, you can actually have a look at the catmap-lambda-if-then-else
expression the comprehension expanded to:
.sp
.nf
> \fBshow\fP primes
primes n = sieve (2..n) \fBwith\fP sieve [] = []; sieve (p:qs) = p:sieve
(catmap (\eq -> if q mod p then [q] else []) qs) \fBend\fP;
.fi
.PP
List comprehensions are also a useful device to organize backtracking
searches. For instance, here's an algorithm for the n queens problem, which
returns the list of all placements of n queens on an n x n board (encoded as
lists of n pairs (i,j) with i = 1..n), so that no two queens hold each other
in check.
.sp
.nf
queens n       = search n 1 [] \fBwith\fP
  search n i p = [reverse p] \fBif\fP i>n;
               = cat [search n (i+1) ((i,j):p) | j = 1..n; safe (i,j) p];
  safe (i,j) p = ~any (check (i,j)) p;
  check (i1,j1) (i2,j2)
               = i1==i2 || j1==j2 || i1+j1==i2+j2 || i1-j1==i2-j2;
\fBend\fP;
.fi
.SS Lazy Evaluation and Streams
As already mentioned, lists can also be evaluated in a ``lazy'' fashion, by
just turning the tail of a list into a
.IR future .
This special kind of list is also called a
.IR stream .
Streams enable you to work with infinite lists (or finite lists which are so
huge that you would never want to keep them in memory in their
entirety). E.g., here's one way to define the infinite stream of all Fibonacci
numbers:
.sp
.nf
> \fBlet\fP fibs = fibs 0L 1L \fBwith\fP fibs a b = a : fibs b (a+b) & \fBend\fP;
> fibs;
0L:#<thunk 0xb5d54320>
.fi
.PP
Note the `&' on the tail of the list in the definition of the local `fibs'
function. This turns the result of `fibs' into a stream, which is required to
prevent the function from recursing into samadhi. Also note that we work with
bigints in this example because the Fibonacci numbers grow quite rapidly, so
with machine integers the values would soon start wrapping around to negative
integers.
.PP
Streams like these can be worked with in pretty much the same way as with
lists. Of course, care must be taken not to invoke ``eager'' operations such
as `#' (which computes the size of a list) on infinite streams, to prevent
infinite recursion. However, many list operations work with infinite streams
just fine, and return the appropriate stream results. E.g., the `take'
function (which retrieves a given number of elements from the front of a list)
works with streams just as well as with ``eager'' lists:
.sp
.nf
> take 10 fibs;
0L:#<thunk 0xb5d54350>
.fi
.PP
Hmm, not much progress there, but that's just how streams work (or rather they
don't, they're lazy bums indeed!). Nevertheless, the stream computed with
`take' is in fact finite and we can readily convert it to an ordinary list,
forcing its evaluation:
.sp
.nf
> list (take 10 fibs);
[0L,1L,1L,2L,3L,5L,8L,13L,21L,34L]
.fi
.PP
An easier way to achieve this is to cut a ``slice'' from the stream:
.sp
.nf
> fibs!!(0..10);
[0L,1L,1L,2L,3L,5L,8L,13L,21L,34L,55L]
.fi
.PP
Also note that since we bound the stream to a variable, the already computed
prefix of the stream has been memoized, so that this portion of the stream is
now readily available in case we need to have another look at it later. By
these means, possibly costly reevaluations are avoided, trading memory for
execution speed.
.sp
.nf
> fibs;
0L:1L:1L:2L:3L:5L:8L:13L:21L:34L:55L:#<thunk 0xb5d54590>
.fi
.PP
Let's take a look at some of the other convenience operations for generating
stream values. The prelude defines infinite arithmetic sequences, using
.B inf
or
.B -inf
to denote an upper (or lower) infinite bound for the sequence, e.g.:
.sp
.nf
> \fBlet\fP u = 1..inf; \fBlet\fP v = -1.0:-1.2..-inf;
> u!!(0..10); v!!(0..10);
[1,2,3,4,5,6,7,8,9,10,11]
[-1.0,-1.2,-1.4,-1.6,-1.8,-2.0,-2.2,-2.4,-2.6,-2.8,-3.0]
.fi
.PP
Other useful stream generator functions are `iterate', `repeat' and `cycle',
which have been adopted from Haskell. In fact, infinite arithmetic
progressions are implemented in terms of `iterate'. The `repeat' function just
repeats its argument, and `cycle' cycles through the elements of the given
list:
.sp
.nf
> repeat 1!!(0..10);
[1,1,1,1,1,1,1,1,1,1,1]
> cycle [0,1]!!(0..10);
[0,1,0,1,0,1,0,1,0,1,0]
.fi
.PP
Moreover, list comprehensions can draw values from streams and return the
appropriate stream result:
.sp
.nf
> \fBlet\fP rats = [m,n-m | n=2..inf; m=1..n-1; gcd m (n-m) == 1]; rats;
(1,1):#<thunk 0xb5d54950>
> rats!!(0..10);
[(1,1),(1,2),(2,1),(1,3),(3,1),(1,4),(2,3),(3,2),(4,1),(1,5),(5,1)]
.fi
.PP
Finally, let's rewrite our prime sieve so that it generates the infinite
stream of
.I all
prime numbers:
.sp
.nf
all_primes      = sieve (2..inf) \fBwith\fP
  sieve (p:qs)  = p : sieve [q | q = qs; q mod p] &;
\fBend\fP;
.fi
.sp
Note that we can omit the empty list case of `sieve' here, since the sieve now
never becomes empty. Example:
.sp
.nf
> \fBlet\fP P = all_primes;
> P!!(0..20);
[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73]
> P!299;
1987
.fi
.PP
You can also just print the entire stream. This will run forever, so hit
Ctrl-C when you get bored.
.sp
.nf
> \fBusing\fP system;
> do (printf "%d\en") all_primes;
2
3
5
  ...
.fi
.PP
(Make sure that you really use the `all_primes' function instead of the P
variable to print the stream. Otherwise, because of memoization the stream
stored in P will grow with the number of elements printed until memory is
exhausted. Calling `do' on a fresh instance of the stream of primes allows
`do' to get rid of each `cons' cell after having printed the corresponding
stream element.)
.SS Matrix Computations
Pure offers a number of basic matrix operations, such as matrix construction,
indexing, slicing, as well as getting the size and dimensions of a matrix
(these are briefly described in the \fISTANDARD LIBRARY\fP section
below). However, it does
.I not
supply built-in support for matrix arithmetic and other linear algebra
algorithms. The idea is that these can and should be provided through separate
libraries (please check the Pure website for the
.B pure-gsl
module which is an ongoing project to provide a full GSL interface for the
Pure language).
.PP
But Pure's facilities for matrix and list processing also make it easy to roll
your own, if desired. First, the prelude provides matrix versions of the
common list operations like map, fold, zip etc., which provide a way to
implement common matrix operations. E.g., multiplying a matrix x with a scalar
a amounts to mapping the function \ex->a*x to x, which can be done as follows:
.sp
.nf
> a * x::matrix = map (\ex->a*x) x \fBif\fP ~matrixp a;
> 2*{1,2,3;4,5,6};
{2,4,6;8,10,12}
.fi
.PP
Likewise, matrix addition and other element-wise operations can be realized
using zipwith, which combines corresponding elements of two matrices using a
given binary function:
.sp
.nf
> x::matrix + y::matrix = zipwith (+) x y;
> {1,2,3;4,5,6}+{1,2,1;3,2,3};
{2,4,4;7,7,9}
.fi
.PP
Second, matrix comprehensions make it easy to express a variety of algorithms
which would typically be implemented using `for' loops in conventional
programming languages. To illustrate the use of matrix comprehensions, here is
how we can define an operation to create a square identity matrix of a given
dimension:
.sp
.nf
> eye n = {i==j | i = 1..n; j = 1..n};
> eye 3;
{1,0,0;0,1,0;0,0,1}
.fi
.PP
Note that the i==j term is just a Pure idiom for the Kronecker symbol. Another
point worth mentioning here is that the generator clauses of matrix
comprehensions alternate between row and column generation
automatically. (More precisely, the last generator, which varies most quickly,
always yields a row, the next-to-last one a column of these row vectors, and
so on.) This makes matrix comprehensions resemble customary mathematical
notation very closely.
.PP
As a slightly more comprehensive example (no pun intended!), here is a
definition of matrix multiplication in Pure. The building block here is the
``dot'' product of two vectors which can be defined as follows:
.sp
.nf
> dot x::matrix y::matrix = foldl (+) 0 [x!i*y!i | i=0..#x-1];
> dot {1,2,3} {1,0,1};
4
.fi
.PP
(For the sake of simplicity, this doesn't do much error checking; if the two
vectors aren't the same size then you'll get an `out_of_bounds' exception with
the definition above.)
.PP
The general matrix product now boils down to a simple matrix comprehension
which just computes the dot product of all rows of x with all columns of y
(the rows and cols functions are prelude operations found in matrices.pure):
.sp
.nf
> x::matrix * y::matrix = {dot u v | u = rows x; v = cols y};
> {0,1;1,0;1,1}*{1,2,3;4,5,6};
{4,5,6;1,2,3;5,7,9}
.fi
.PP
Well, that was easy. So let's take a look at a more challenging example,
Gaussian elimination, which can be used to solve systems of linear
equations. The algorithm brings a matrix into ``row echelon'' form, a
generalization of triangular matrices. The resulting system can then be solved
quite easily using back substitution. Here is a Pure implementation of the
algorithm:
.sp
.nf
gauss_elimination x::matrix = p,x
\fBwhen\fP n,m = dim x; p,_,x = foldl step (0..n-1,0,x) (0..m-1) \fBend\fP;

// One pivoting and elimination step in column j of the matrix:
step (p,i,x) j
= \fBif\fP max_x==0 \fBthen\fP p,i,x
  \fBelse\fP
    // updated row permutation and index:
    transp i max_i p, i+1,
    {// the top rows of the matrix remain unchanged:
     x!!(0..i-1,0..m-1);
     // the pivot row, divided by the pivot element:
     {x!(i,l)/x!(i,j)                 | l=0..m-1};
     // subtract suitable multiples of the pivot row:
     {x!(k,l)-x!(k,j)*x!(i,l)/x!(i,j) | k=i+1..n-1; l=0..m-1}}
\fBwhen\fP
  n,m = dim x; max_i, max_x = pivot i (col x j);
  x = \fBif\fP max_x>0 \fBthen\fP swap x i max_i \fBelse\fP x;
\fBend\fP \fBwith\fP
  pivot i x       = foldl max (0,0) [j,abs (x!j)|j=i..#x-1];
  max (i,x) (j,y) = \fBif\fP x<y \fBthen\fP j,y \fBelse\fP i,x;
\fBend\fP;
.fi
.PP
The real meat is in the pivoting and elimination step (`step' function) which
is iterated over all columns of the input matrix. In each step, x is the
current matrix, i the current row index, j the current column index, and p
keeps track of the current permutation of the row indices performed during
pivoting. The algorithm returns the updated matrix x, row index i and row
permutation p.
.PP
Please refer to any good textbook on numerical mathematics for a closer
description of the algorithm. But here is a brief rundown of what happens in
each elimination step: First we find the pivot element in column j of the
matrix. (We're doing partial pivoting here, i.e., we only look for the element
with the largest absolute value in column j, starting at row i. That's usually
good enough to achieve numerical stability.) If the pivot is zero then we're
done (the rest of the pivot column is already zeroed out). Otherwise, we bring
it into the pivot position (swapping row i and the pivot row), divide the
pivot row by the pivot, and subtract suitable multiples of the pivot row to
eliminate the elements of the pivot column in all subsequent rows. Finally we
update i and p accordingly and return the result.
.PP
In order to complete the implementation, we still need the following little
helper functions to swap two rows of a matrix (this is used in the pivoting
step) and to apply a transposition to a permutation (represented as a list):
.sp
.nf
swap x i j = x!!(transp i j (0..n-1),0..m-1) \fBwhen\fP n,m = dim x \fBend\fP;
transp i j p = [p!tr k | k=0..#p-1]
\fBwith\fP tr k = \fBif\fP k==i \fBthen\fP j \fBelse\fP \fBif\fP k==j \fBthen\fP i \fBelse\fP k \fBend\fP;
.fi
.PP
Finally, let us define a convenient print representation of double matrices a
la Octave (the meaning of the __show__ function is explained in the \fICAVEATS
AND NOTES\fP section):
.sp
.nf
\fBusing\fP system;
__show__ x::matrix
= strcat [printd j (x!(i,j))|i=0..n-1; j=0..m-1] + "\en"
\fBwith\fP printd 0 = sprintf "\en%10.5f"; printd _ = sprintf "%10.5f" \fBend\fP
\fBwhen\fP n,m = dim x \fBend\fP \fBif\fP dmatrixp x;
.fi
.PP
Example:
.sp
.nf
> \fBlet\fP x = dmatrix {2,1,-1,8; -3,-1,2,-11; -2,1,2,-3};
> x; gauss_elimination x;

   2.00000   1.00000  -1.00000   8.00000
  -3.00000  -1.00000   2.00000 -11.00000
  -2.00000   1.00000   2.00000  -3.00000

[1,2,0],
   1.00000   0.33333  -0.66667   3.66667
   0.00000   1.00000   0.40000   2.60000
   0.00000   0.00000   1.00000  -1.00000
.fi
.SH MACROS
Macros are a special type of functions to be executed as a kind of
``preprocessing stage'' at compile time. In Pure these are typically used to
define custom special forms and to perform inlining of function calls and
other simple kinds of source-level optimizations.
.PP
Whereas the macro facilities of most programming languages simply provide a
kind of textual substitution mechanism, Pure macros operate on symbolic
expressions and are implemented by the same kind of rewriting rules that are
also used to define ordinary functions in Pure. In difference to these, macro
rules start out with the keyword
.BR def ,
and only simple kinds of rules without any guards or multiple left-hand and
right-hand sides are permitted.
.PP
Syntactically, a macro definition looks just like a variable or constant
definition, using
.B def
in lieu of
.B let
or
.BR const ,
but they are processed in a different way. Macros are substituted into the
right-hand sides of function, constant and variable definitions. All macro
substitution happens before constant substitutions and the actual compilation
step. Macros can be defined in terms of other macros (also recursively), and
are evaluated using call by value (i.e., macro calls in macro arguments are
expanded before the macro gets applied to its parameters).
.SS Optimization Rules
Here is a simple example, showing a rule which expands saturated calls of the
.B succ
function (defined in the prelude) at compile time:
.sp
.nf
> \fBdef\fP succ x = x+1;
> foo x::int = succ (succ x);
> \fBshow\fP foo
foo x::int = x+1+1;
.fi
.PP
Rules like these can be useful to help the compiler generate better code. Note
that a macro may have the same name as an ordinary Pure function, which is
essential if you want to optimize calls to an existing function, as in the
previous example. (Just like ordinary functions, the number of parameters in
each rule for a given macro must be the same, but a macro may have a different
arity than the corresponding function.)
.PP
A somewhat more practical example is the following rule from the prelude,
which eliminates saturated instances of the right-associative function
application operator:
.sp
.nf
\fBdef\fP f $ x = f x;
.fi
.PP
Like in Haskell, this low-priority operator is handy to write cascading
function calls. With the above macro rule, these will be ``inlined'' as
ordinary function applications automagically. Example:
.sp
.nf
> foo x = bar $ bar $ 2*x;
> \fBshow\fP foo
foo x = bar (bar (2*x));
.fi
.PP
Here is slightly more tricky rule from the prelude, which optimizes the case
of ``throwaway'' list comprehensions. This is useful if a list comprehension
is evaluated solely for its side effects.
.sp
.nf
\fBdef\fP void (catmap f x) = do f x;
.fi
.PP
Note that the `void' function simply throws away its argument and returns ()
instead. The `do' function applies a function to every member of a list (like
`map'), but throws away all intermediate results and just returns (), which is
much more efficient if you don't need those results anyway. These are both
defined in the prelude.
.PP
Let's see how this rule transforms a list comprehension if we ``voidify'' it:
.sp
.nf
> \fBusing\fP system;
> f = [printf "%g\en" (2^x+1) | x=1..5; x mod 2];
> g = void [printf "%g\en" (2^x+1) | x=1..5; x mod 2];
> \fBshow\fP f g
f = catmap (\ex -> if x mod 2 then [printf "%g\en" (2^x+1)] else []) (1..5);
g = do (\ex -> if x mod 2 then [printf "%g\en" (2^x+1)] else []) (1..5);
.fi
.PP
Ok, so the `catmap' got replaced with a `do' which is just what we need to
make this code go essentially as fast as a `for' loop in conventional
programming languages (up to constant factors, of course). Here's how it looks
like when we run the `g' function:
.sp
.nf
> g;
3
9
33
()
.fi
.PP
It's not all roses, however, since the above macro rule will only get rid of
the outermost `catmap' if the list comprehension binds multiple variables:
.sp
.nf
> u = void [puts $ str (x,y) | x=1..2; y=1..3];
> \fBshow\fP u
u = do (\ex -> catmap (\ey -> [puts (str (x,y))]) (1..3)) (1..2);
.fi
.PP
If you're bothered by this, you'll have to apply `void' recursively, creating
a nested list comprehension which expands to a nested `do':
.sp
.nf
> v = void [void [puts $ str (x,y) | y=1..3] | x=1..2];
> \fBshow\fP v
v = do (\ex -> [do (\ey -> [puts (str (x,y))]) (1..3)]) (1..2);
.fi
.PP
(It would be nice to have this handled automatically, but the left-hand side
of a macro definition must be a simple expression, and thus it's not possible
to write a macro which descends recursively into the lambda argument of
`catmap'.)
.SS Recursive Macros
Macros can also be recursive, in which case they usually consist of multiple
rules and make use of pattern-matching like ordinary function definitions. As
a simple example, let's have a look at Pure's version of Lisp's quasiquote
from the prelude:
.sp
.nf
\fBdef\fP quasiquote (unquote x)      = x;
\fBdef\fP quasiquote (f@_ (splice x)) = foldl ($) (quasiquote f)
                                  (quasiquote x);
\fBdef\fP quasiquote (f@_ x)          = quasiquote f (quasiquote x);
\fBdef\fP quasiquote x                = quote x;
.fi
.PP
(Note the `f@_', which is an anonymous ``as'' pattern forcing the compiler to
recognize `f' as a function variable, rather than a literal function
symbol. See \fIHead = Function\fP in the \fICAVEATS AND NOTES\fP section for
an explanation of this trick.)
.PP
The first rule above takes care of ``unquoting'' embedded subterms. The second
rule ``splices'' an argument list into an enclosing function application. The
third rule recurses into subterms of a function application, and the fourth
and last rule takes care of quoting the ``atomic'' subterms. Note that
.B unquote
and
.B splice
themselves are just passive constructor symbols, the real work is done by
.BR quasiquote ,
using
.B foldl
at runtime to actually perform the splicing. (Putting off the splicing until
runtime makes it possible to splice argument lists computed at runtime.)
.PP
If we want, we can also add some syntactic sugar for Lisp weenies. (This isn't
in the prelude, so you'll have to define it yourself. Also note that we cannot
have `,' for unquoting, so we use `,,' instead.)
.sp
.nf
\fBprefix\fP 9 ` ,, ,@ ;
\fBdef\fP `x = quasiquote x; \fBdef\fP ,,x = unquote x; \fBdef\fP ,@x = splice x;
.fi
.PP
Examples:
.sp
.nf
> `(2*42+2^12);
2*42+2^12
> `(2*42+,,(2^12));
2*42+4096.0
> `foo 1 2 (,@[2/3,3/4]) (5/6);
foo 1 2 (2/3) (3/4) (5/6)
> `foo 1 2 (,@args) (5/6) \fBwhen\fP args = quote [2/3,3/4] \fBend\fP;
foo 1 2 (2/3) (3/4) (5/6)
.fi
.PP
Note that, technically, Pure macros are just as powerful as (unconditional)
term rewriting systems and thus they are Turing-complete. This implies that a
badly written macro may well send the Pure compiler into an infinite
recursion, which results in a stack overflow at compile time. See the
\fICAVEATS AND NOTES\fP section at the end of this manual for information on
how to deal with these by setting the
.B PURE_STACK
environment variable.
.SS User-Defined Special Forms
The
.B quasiquote
macro in the preceding subsection also provides an example of how you can use
macros to define your own special forms. This works because the actual
evaluation of macro arguments is put off until runtime, and thus we can safely
pass them to built-in special forms and other constructs which defer their
evaluation \fIat runtime\fP. In fact, the right-hand side of a macro rule may
be an arbitrary Pure expression involving conditional expressions, lambdas,
binding clauses, etc. These are
.I never
evaluated during macro substitution, they just become part of the macro
expansion (after substituting the macro parameters).
.PP
Here is another useful example of a user-defined special form, the macro
`timex' which employs the system function `clock' to report the cpu time in
seconds needed to evaluate a given expression, along with the computed result:
.sp
.nf
> \fBusing\fP system;
> \fBdef\fP timex x = (clock-t0)/CLOCKS_PER_SEC,y \fBwhen\fP t0 = clock; y = x \fBend\fP;
> sum = foldl (+) 0L;
> timex $ sum (1L..100000L);
0.43,5000050000L
.fi
.PP
Note that the above definition of `timex' wouldn't work as an ordinary
function definition, since by virtue of Pure's basic eager evaluation strategy
the x parameter would have been evaluated already before it is passed to
`timex', making `timex' always return a zero time value. Try it!
.PP
Here's yet another example, which is handy if you need to trace function calls
for debugging purposes:
.sp
.nf
\fBusing\fP system;
\fBdef\fP trace f x y = printf "** exit %s: %s -> %s\en" (str f,str x,str y) $$ y
\fBwhen\fP y = printf "** call %s: %s\en: " (str f,str x) $$ gets $$ y \fBend\fP;
.fi
.PP
This macro is invoked with the function to be traced, the arguments (or
whatever you want to be printed as additional debugging information) and the
actual function call as parameters. (This is a rather simplistic version,
which just prints a prompt on function entry and the final reduction after the
call. You can easily make this as elaborate as you like. E.g., you might want
to keep track of recursive levels and profiling information, add various
interactive commands to selectively enable and disable tracing during the
evaluation, etc.)
.PP
We can still make this a bit more convenient by introducing the following
ordinary function definition:
.sp
.nf
trace f x = trace f x (f x);
.fi
.PP
This lets us patch up a call to trace a given function, as shown below,
without having to change the definition of the function at all. Alas, this
trick only works with global functions; for local functions you'll have to add
an explicit call of the `trace' macro to the local definition yourself. Also
note that the definition above only works with functions taking a single
parameter; see the trace.pure example in the distribution for the full version
which can deal with any number of arguments.
.sp
.nf
// Uncomment this line to trace calls to the 'fact' function.
\fBdef\fP fact n = trace fact n;
// Sample function to be traced.
fact n = \fBif\fP n>0 \fBthen\fP n*fact(n-1) \fBelse\fP 1;
.fi
.PP
Here's a trace of the `fact' function obtained in this fashion (hit carriage
return after each `:' prompt to proceed with the computation):
.sp
.nf
> fact 2;
** call fact: 2
: 
** call fact: 1
: 
** call fact: 0
: 
** exit fact: 0 -> 1
** exit fact: 1 -> 1
** exit fact: 2 -> 2
2
.fi
.PP
Note that by just removing the macro definition for `fact' above, you can make
the function run untraced as usual again. This scheme is quite flexible, the
only real drawback is that you have to explicitly add some code for each
function you want to trace. A future version of the interpreter might provide
some built-in support to make this more convenient, but for the time being our
little `trace' macro does the job quite well for most purposes.
.SS Macro Hygiene
Pure macros are lexically scoped, i.e., symbols on the right-hand-side of a
macro definition can never refer to anything outside the macro definition, and
macro parameter substitution also takes into account binding constructs, such
as
.B with
and
.B when
clauses, in the right-hand side of the definition. Macro facilities with these
pleasant properties are also known as
.I hygienic
macros. They are not susceptible to so-called ``name capture,'' which makes
macros in less sophisticated languages bug-ridden and hard to use.
.PP
Pure macros also have their limitations. Specifically, the left-hand side of a
macro rule must be a simple expression, just like in ordinary function
definitions. This restricts the kinds of expressions which can be rewritten by
a macro. But Pure macros are certainly powerful enough for most common
preprocessing purposes, while still being robust and easy to use.
.SH DECLARATIONS
Pure is a very terse language by design. Usually you don't declare much stuff,
you just define it and be done with it. However, there are a few toplevel
constructs which let you declare symbols with special attributes and manage
programs consisting of several source modules. These are: explicit symbol
declarations which determine ``scope'' and ``fixity'' of a symbol,
.B extern
declarations for external C functions (described in the \fIC INTERFACE\fP
section),
.B using
clauses which let you include other scripts in a Pure script, and
.B namespace
declarations which make it easier to manage large programs consisting of many
separate modules.
.TP
\fBScope declarations:\fP \fBpublic\fP \fIsymbol\fP ...; \fBprivate\fP \fIsymbol\fP ...;
Declares the listed symbols as
.I public
or
.IR private ,
respectively. All identifiers without an explicit prior declaration default to
public scope, which means that they are visible everywhere in a program. An
explicit
.B public
declaration of ordinary identifiers is thus rarely needed, unless you want to
declare symbols as members of a specific
.IR namespace .
Symbols can also be declared
.BR private ,
meaning that the symbol is visible only in the namespace it belongs to. This
is explained in more detail under \fINamespaces\fP below.
.sp
The
.B public
and
.B private
keywords can also be used as a prefix in any of the special symbol
declarations discussed below, to specify the scope of the declared symbols (if
the scope prefix is omitted, it defaults to
.BR public ).
Also note that to declare multiple symbols in a single declaration, you just
list them all with whitespace in between. The same applies to the other types
of symbol declarations discussed below.
.TP
\fBOperator declarations:\fP \fBinfix\fP \fIlevel op\fP ...;
Ten different precedence levels are available for user-defined operators,
numbered 0 (lowest) thru 9 (highest). On each precedence level, you can
declare (in order of increasing precedence)
.BR infix " (binary non-associative),"
.BR infixl " (binary left-associative),"
.BR infixr " (binary right-associative),"
.BR prefix " (unary prefix) and"
.BR postfix " (unary postfix)"
operators. For instance:
.sp
.nf
\fBinfixl\fP 6 + - ;
\fBinfixl\fP 7 * / div mod ;
.fi
.sp
One thing worth noting here is that unary minus plays a special role in the
syntax. Like in Haskell, unary minus is the only prefix operator symbol which
is also used as an infix operator, and it always has the same precedence as
binary minus (whose precedence may be chosen freely in the prelude). Thus,
with the standard prelude, -x+y will be parsed as (-x)+y, whereas -x*y is the
same as -(x*y). Also note that the notation `(-)' always denotes the binary
minus operator; the unary minus operation can be denoted using the built-in
`neg' function.
.TP
\fBConstant symbol declarations:\fP \fBnullary\fP \fIsymbol\fP ...;
Constant symbols are introduced using a
.B nullary
declaration, e.g.:
.sp
.nf
\fBnullary\fP foo;
.fi
.sp
As explained in the \fIPURE OVERVIEW\fP section,
.B nullary
symbols are like ordinary identifiers, but are treated as constants rather
than variables when they occur on the left-hand side of an equation.
.TP
\fBUsing clause:\fP \fBusing\fP \fIname\fP, ...;
Causes each given script to be included in the Pure program. Each included
script is loaded only
.IR once ,
when the first
.B using
clause for the script is encountered. Note that the
.B using
clause also has an alternative form which allows dynamic libraries to be
loaded, this will be discussed in the \fIC INTERFACE\fP section.
.TP
\fBNamespace declarations:\fP \fBnamespace\fP \fIname\fP; \fBusing\fP \fBnamespace\fP \fIname\fP, ...;
These declarations allow you to create new namespaces and then later use them
in your program. This provides a means to avoid name collisions and hide away
internal operations, which makes it easier to manage programs and libraries
consisting of a large number of different modules.
.PP
Examples for all types of symbol declarations can be found in the prelude
which declares a bunch of standard (arithmetic, relational, logical) operator
symbols as well as the list and pair constructors `:' and `,', and a few
nullary symbols (mostly for denoting different kinds of exceptions). The
.B using
and
.B namespace
declarations are discussed in further detail below.
.SS Modules
While Pure doesn't offer separate compilation, the
.B using
declaration provides a simple but effective way to assemble a Pure program
from several source modules. The Pure program is basically the concatenation
of all the source modules listed as command line arguments. A
.B using
clause instructs the compiler to include the corresponding source script at
this point, which makes available all the definitions in the included script
in your program. Each script only gets included once, at the point where the
first
.B using
clause for the script is encountered.
.PP
The script name in a
.B using
clause can be specified either as a string denoting the proper filename
(possibly including path and/or filename extension), or as an identifier. In
the latter case, the
.B .pure
filename extension is added automatically. In both cases, the interpreter
performs a search to locate the script, unless an absolute pathname was
given. It first searches the directory of the script containing the
.B using
clause (or the current working directory if the clause was read from standard
input, as is the case, e.g., in an interactive session), then the directories
named in
.B -I
options on the command line (in the given order), then the colon-separated
list of directories in the
.B PURE_INCLUDE
environment variable, and finally the directory named by the
.B PURELIB
environment variable. Note that the current working directory is \fInot\fP
searched by default (unless the
.B using
clause is read from standard input), but of course you can force this by
adding the option
.B -I.
to the command line, or by including `.' in the
.B PURE_INCLUDE
variable.
.PP
For the purpose of comparing script names, the interpreter always uses the
canonicalized full pathname of the script, following symbolic links to the
destination file (albeit only one level). Thus different scripts with the same
basename, such as
.B foo/utils.pure
and
.B bar/utils.pure
can both be included in the same program (unless they link to the same
file). The resolution of symbolic links also makes it possible to have an
executable script with a shebang line in its own directory, to be executed via
a symbolic link placed on the system
.BR PATH .
In this case the script search performed in
.B using
clauses will use the real script directory and thus other required scripts can
be located there. This is the recommended practice for installing standalone
Pure applications in source form which are to be run directly from the shell.
.SS Namespaces
To facilitate modular development, Pure also provides
.I namespaces
as a means to avoid name clashes between symbols of different modules, and to
keep the global namespace tidy and clean. The global namespace is always
available. By default, new symbols are created in this namespace, which is
also called the
.I default
namespace.
.PP
Additional namespaces can be created with the
.B namespace
declaration, which also switches to the given namespace (makes it the
.I current
namespace), so that subsequent symbol declarations create symbols in that
namespace rather than the default one. The current namespace applies to all
kinds of symbol declarations, including operator and nullary symbol
declarations, as well as
.B extern
declarations (the latter are described in the \fIC INTERFACE\fP section).
.PP
For instance, in order to create two symbols with the same print name `foo' in
two different namespaces `foo' and `bar', you can write:
.sp
.nf
\fBnamespace\fP foo;
\fBpublic\fP foo;
foo x = x+1;
\fBnamespace\fP bar;
\fBpublic\fP foo;
foo x = x-1;
\fBnamespace\fP;
.fi
.PP
Note that just the
.B namespace
keyword by itself in the last line switches back to the default namespace.
We can now refer to the symbols we just defined using
.I qualified
symbols of the form \fInamespace\fP::\fIsymbol\fP:
.sp
.nf
> foo::foo 99;
100
> bar::foo 99;
98
.fi
.PP
This avoids any potential name clashes, since the qualified identifier
notation always makes it clear which namespace the given identifier belongs
to. (The namespace prefix in a qualified symbol can also be empty in which
case it explicitly denotes a symbol in the default namespace.)
.PP
Since it is rather inconvenient if you always have to write identifiers in
their fully qualified form, Pure allows you to specify a list of
.I search
namespaces which are to be searched for unqualified symbols. This is done with
the
.B using namespace
declaration, as follows:
.sp
.nf
> \fBusing\fP \fBnamespace\fP foo;
> foo 99;
100
> \fBusing\fP \fBnamespace\fP bar;
> foo 99;
98
.fi
.PP
The
.B using namespace
declaration also lets you search multiple namespaces simultaneously:
.sp
.nf
\fBusing\fP \fBnamespace\fP foo, bar;
.fi
.PP
However, this requires that an unqualified identifier exists in at most one of
the listed namespaces, otherwise you get an error message:
.sp
.nf
> \fBusing\fP \fBnamespace\fP foo, bar;
> foo 99;
<stdin>, line 15: symbol 'foo' is ambiguous here
.fi
.PP
In such a case you have to use the appropriate namespace qualifier to resolve
the name clash:
.sp
.nf
> foo::foo 99;
100
.fi
.PP
A
.B using namespace
declaration without any namespace arguments gets you back to the default
empty list of search namespaces:
.sp
.nf
\fBusing\fP \fBnamespace\fP;
.fi
.PP
The precise rules for looking up unqualified identifiers are as follows. The
compiler searches for unqualified symbols first in the current namespace (if
any), then in the currently active search namespaces (if any), and finally in
the default (i.e., the global) namespace, in that order. If no existing symbol
is found, a new symbol is created, implicitly declaring the identifier as a
public symbol with default attributes. New
.I unqualified
symbols are always created in the default namespace, unless you explicitly
declare them (in which case they become members of the current namespace, as
explained above). New
.I qualified
symbols are created in the given namespace (which must already exist). This
makes it possible to avoid explicit symbol declarations in the most common
case of ordinary, public identifiers. E.g., we could have written the above
example simply as follows:
.sp
.nf
\fBnamespace\fP foo;
foo::foo x = x+1;
\fBnamespace\fP bar;
bar::foo x = x-1;
\fBnamespace\fP;
.fi
.PP
As a little safety measure against silly typos, the compiler warns you about
implicit declarations of new qualified symbols which are created out of their
``home'' namespace:
.sp
.nf
> \fBnamespace\fP;
> foo::bar x = 1/x;
<stdin>, line 6: warning: implicit declaration of symbol 'foo::bar'
.fi
.PP
To avoid these warnings, you either have to use an explicit declaration or
make sure that the right namespace is current when introducing the symbol.
.PP
Explicit declarations are also needed if you want to introduce special
operator and nullary symbols. This works just like in the default namespace,
except that you add the appropriate
.B namespace
declaration before declaring the symbols. For instance, here is how you can
create a new `+' operation which multiplies its operands rather than adding
them:
.sp
.nf
> \fBnamespace\fP my;
> \fBinfixl\fP 6 +;
> x+y = x*y;
> 5+7;
35
.fi
.PP
Note that the new `+' operation really belongs to the namespace we
created. The `+' operation in the default namespace works as before, and in
fact you can use qualified symbols to pick the version that you need:
.sp
.nf
> \fBnamespace\fP;
> 5+7;
12
> 5 ::+ 7;
12
> 5 my::+ 7;
35
.fi
.PP
Pure also allows you to have
.I private
symbols, as a means to hide away internal operations which shouldn't be
accessed directly by client programs. The scope of a private symbol is
confined to its namespace, i.e., the symbol is only visible when its ``home''
namespace is current. Symbols are declared private by using the
.B private
keyword in the symbol declaration:
.sp
.nf
> \fBnamespace\fP secret;
> \fBprivate\fP baz;
> // 'baz' is a private symbol in namespace 'secret' here
> baz x = 2*x;
> // you can use 'baz' just like any other symbol here
> baz 99;
198
> \fBnamespace\fP;
.fi
.PP
Note that, at this point, secret::baz is now invisible, even if you
have `secret' in the search namespace list:
.sp
.nf
> \fBusing\fP \fBnamespace\fP secret;
> // this actually creates a 'baz' symbol in the default namespace:
> baz 99;
baz 99
> secret::baz 99;
<stdin>, line 27: symbol 'secret::baz' is private here
.fi
.PP
The only way to bring the symbol back into scope is to make the `secret'
namespace current again:
.sp
.nf
> \fBnamespace\fP secret;
> baz 99;
198
> secret::baz 99;
198
.fi
.PP
Finally, note that, similar to the
.B using
declaration, a
.B namespace
or
.B using namespace
declaration accepts either identifiers or double-quoted strings as namespace
names. E.g., the following two declarations are in fact equivalent:
.sp
.nf
\fBnamespace\fP foo;
\fBnamespace\fP "foo";
.fi
.PP
The latter form also allows more descriptive labels which aren't identifiers,
e.g.:
.sp
.nf
\fBnamespace\fP "Private stuff, keep out!";
.fi
.PP
Note that the namespace prefix in a qualified identifier
.I must
be a legal identifier, so it isn't possible to access symbols in namespaces
with such descriptive labels in a direct fashion; the only way to get at the
symbols in this case is to use a
.B namespace
or
.B using namespace
declaration.
.SH EXCEPTION HANDLING
Pure also offers a useful exception handling facility. To raise an exception,
you just invoke the built-in function
.B throw
with the value to be thrown as the argument. To catch an exception, you use
the built-in special form
.B catch
with the exception handler (a function to be applied to the exception value)
as the first and the expression to be evaluated as the second (call-by-name)
argument. For instance:
.sp
.nf
> catch error (throw hello_world);
error hello_world
.fi
.PP
Exceptions are also generated by the runtime system if the program runs out of
stack space, when a guard does not evaluate to a truth value, and when the
subject term fails to match the pattern in a pattern-matching lambda
abstraction, or a \fBlet\fP, \fBcase\fP or \fBwhen\fP construct. These types
of exceptions are reported using the symbols
.BR stack_fault ,
.B failed_cond
and
.BR failed_match ,
respectively, which are declared as constant symbols in the standard
prelude. You can use
.B catch
to handle these kinds of exceptions just like any other. For instance:
.sp
.nf
> fact n = \fBif\fP n>0 \fBthen\fP n*fact(n-1) \fBelse\fP 1;
> catch error (fact foo);
error failed_cond
> catch error (fact 100000);
error stack_fault
.fi
.PP
(You'll only get the latter kind of exception if the interpreter does stack
checks, see the discussion of the
.B PURE_STACK
environment variable in the \fICAVEATS AND NOTES\fP section.)
.PP
Note that unhandled exceptions are reported by the interpreter with a
corresponding error message:
.sp
.nf
> fact foo;
<stdin>, line 2: unhandled exception 'failed_cond' while evaluating
 'fact foo'
.fi
.PP
Exceptions also provide a way to handle asynchronous signals. Most standard
termination signals (SIGINT, SIGTERM, etc.) are set up during startup of the
interpreter to produce corresponding Pure exceptions of the form
.B signal SIG
where
.B SIG
is the signal number. Pure's system module provides symbolic constants for
common POSIX signals and also defines the operation
.B trap
which lets you rebind any signal to a
.B signal
exception. For instance, the following lets you handle the SIGQUIT signal:
.sp
.nf
> \fBusing\fP system;
> trap SIG_TRAP SIGQUIT;
.fi
.PP
You can also use
.B trap
to just ignore a signal or revert to the system's default handler (which might
take different actions depending on the type of signal, see
.BR signal (7)
for details):
.sp
.nf
> trap SIG_IGN SIGQUIT; // signal is ignored
> trap SIG_DFL SIGQUIT; // reinstalls the default signal handler
.fi
.PP
Last but not least, exceptions can also be used to implement non-local value
returns. For instance, here's a variation of our n queens algorithm which only
returns the first solution. Note the use of
.B throw
in the recursive search routine to bail out with a solution as soon as we
found one. The value thrown there is caught in the main routine. Also note the
use of `void' in the second equation of `search'. This effectively turns the
list comprehension into a simple loop which suppresses the normal list result
and just returns () instead. Thus, if no value gets thrown then the function
regularly returns with () to indicate that there is no solution.
.sp
.nf
queens1 n      = catch reverse (search n 1 []) \fBwith\fP
  search n i p = throw p \fBif\fP i>n;
               = void [search n (i+1) ((i,j):p) | j = 1..n; safe (i,j) p];
  safe (i,j) p = ~any (check (i,j)) p;
  check (i1,j1) (i2,j2)
               = i1==i2 || j1==j2 || i1+j1==i2+j2 || i1-j1==i2-j2;
\fBend\fP;
.fi
.PP
E.g., let's compute a solution for a standard 8x8 board:
.sp
.nf
> queens 8;
[(1,1),(2,5),(3,8),(4,6),(5,3),(6,7),(7,2),(8,4)]
.fi
.SH C INTERFACE
Accessing C functions from Pure programs is dead simple. You just need an
.B extern
declaration of the function, which is a simplified kind of C prototype. The
function can then be called in Pure just like any other. For instance, the
following commands, entered interactively in the interpreter, let you use the
.B sin
function from the C library (of course you could just as well put the
.B extern
declaration into a script):
.sp
.nf
> \fBextern\fP double sin(double);
> sin 0.3;
0.29552020666134
.fi
.sp
Multiple prototypes can be given in one
.B extern
declaration, separating them with commas:
.sp
.nf
\fBextern\fP double sin(double), double cos(double), double tan(double);
.fi
.sp
For clarity, the parameter types can also be annotated with parameter names,
e.g.:
.sp
.nf
\fBextern\fP double sin(double x);
.fi
.sp
Parameter names in prototypes only serve informational purposes and are for
the human reader; they are effectively treated as comments by the compiler.
.PP
The interpreter makes sure that the parameters in a call match; if not, the
call is treated as a normal form expression by default, which gives you the
opportunity to extend the external function with your own Pure equations (see
below). The range of supported C types is a bit limited right now (void, bool,
char, short, int, long, float, double, as well as arbitrary pointer types,
i.e.: void*, char*, etc.), but in practice these should cover most kinds of
calls that need to be done when interfacing to C libraries.
.PP
Single precision float arguments and return values are converted from/to
Pure's double precision floating point numbers automatically.
.PP
A variety of C integer types (char, short, int, long) are provided which are
converted from/to the available Pure integer types in a straightforward
way. One important thing to note here is that the `long' type
.I always
denotes 64 bit integers, even if the corresponding C type is actually 32 bit
(as it usually is on most contemporary systems). To make it easier to
interface to various system routines, there's also a special size_t integer
type which usually is 4 bytes on 32 bit and 8 bytes on 64 bit systems. All
integer parameters take both Pure ints and bigints as actual arguments;
truncation or sign extension is performed as needed, so that the C interface
behaves as if the argument was ``cast'' to the C target type. Returned
integers use the smallest Pure type capable of holding the result (i.e., int
for the C char, short and int types, bigint for long a.k.a. 64 bit integers).
.PP
Pure considers all integers as signed quantities, but it is possible to pass
unsigned integers as well (if necessary, you can use a bigint to pass positive
values which are too big to fit into a machine int). Also note that when an
unsigned integer is returned by a C routine which is too big to fit into the
corresponding signed integer type, it will ``wrap around'' and become
negative. In this case, depending on the target type, you can use the ubyte,
ushort, uint and ulong functions provided by the prelude to convert the result
back to an unsigned quantity.
.PP
Concerning the pointer types, char* is for string arguments and return values
which need translation between Pure's internal utf-8 representation and the
system encoding, while void* is for any generic kind of pointer (including
strings, which are \fInot\fP translated when passed/returned as void*). Any
other kind of pointer (except expr* and the GSL matrix pointer types, which
are discussed below) is effectively treated as void* right now, although in a
future version the interpreter may keep track of the type names for the
purpose of checking parameter types.
.PP
The expr* pointer type is special; it indicates a Pure expression parameter or
return value which is just passed through unchanged. All other types of values
have to be ``unboxed'' when they are passed as arguments (i.e., from Pure to
C) and ``boxed'' again when they are returned as function results (from C to
Pure). All of this is handled by the runtime system in a transparent way, of
course.
.PP
The matrix pointer types dmatrix*, cmatrix* and imatrix* can be used to pass
double, complex double and int matrices to GSL functions taking pointers to
the corresponding GSL types (gsl_matrix, gsl_matrix_complex and
gsl_matrix_int) as arguments or returning them as results. Note that there is
no marshalling of Pure's symbolic matrix type, as these aren't supported by
GSL anyway. Also note that matrices are always passed by reference. If you
need to pass a matrix as an output parameter of a GSL matrix routine, you can
either create a zero matrix or a copy of an existing matrix. The prelude
provides various operations for that purpose (in particular, see the dmatrix,
cmatrix, imatrix and pack functions in matrices.pure). For instance, here is
how you can quickly wrap up GSL's double matrix addition function in a way
that preserves value semantics:
.sp
.nf
> \fBextern\fP int gsl_matrix_add(dmatrix*, dmatrix*);
> x::matrix + y::matrix = gsl_matrix_add x y $$ x \fBwhen\fP x = pack x \fBend\fP;
> \fBlet\fP x = dmatrix {1,2,3}; \fBlet\fP y = dmatrix {2,3,2}; x; y; x+y;
{1.0,2.0,3.0}
{2.0,3.0,2.0}
{3.0,5.0,5.0}
.fi
.PP
Most GSL matrix routines can be wrapped in this fashion quite easily. A
ready-made GSL interface providing access to all of GSL's numeric functions
is in the works; please check the Pure website for details.
.PP
For convenience, it is also possible to pass a numeric matrix for a short*,
int*, float* or double* parameter. The required conversions are done
automatically, on the fly, and the matrix data is copied to temporary storage
in order to preserve value sematics.
.PP
In addition, any kind of matrix (including symbolic matrices) can also be
passed for a generic void* pointer. In this case no conversions are done and a
pointer to the raw matrix data is passed, which allows the matrix to be
modified in-place.
.PP
As already mentioned, it is possible to augment an external C function with
ordinary Pure equations, but in this case you have to make sure that the
.B extern
declaration of the function comes first. For instance, we might want to extend
our imported
.B sin
function with a rule to handle integers:
.sp
.nf
> \fBextern\fP double sin(double);
> sin 0.3;
0.29552020666134
> sin 0;
sin 0
> sin x::int = sin (double x);
> sin 0;
0.0
.fi
.PP
Sometimes it is preferable to replace a C function with a wrapper function
written in Pure. In such a case you can specify an \fIalias\fP under which the
original C function is known to the Pure program, so that you can still call
the C function from the wrapper. An alias is introduced by terminating the
.B extern
declaration with a clause of the form ``= \fIalias\fP''. For instance:
.sp
.nf
> \fBextern\fP double sin(double) = c_sin;
> sin x::double = c_sin x;
> sin x::int = c_sin (double x);
> sin 0.3; sin 0;
0.29552020666134
0.0
.fi
.PP
As an alternative, you can also declare the C function in a special namespace
(cf. \fINamespaces\fP in the \fIDECLARATIONS\fP section):
.sp
.nf
> \fBnamespace\fP c;
> \fBextern\fP double sin(double);
> c::sin 0.3;
0.29552020666134
.fi
.PP
Note that the namespace qualification only affects the Pure side; the
underlying C function is still called under the unqualified name as usual.
The way in which such qualified externs are accessed is the same as for
ordinary qualified symbols. In particular, the
.B using namespace
declaration applies as usual, and you can declare such symbols as
.B private
if needed. It is also possible to combine a namespace qualifier with an alias:
.sp
.nf
> \fBnamespace\fP c;
> \fBextern\fP double sin(double) = mysin;
> c::mysin 0.3;
0.29552020666134
.fi
.PP
External C functions are resolved by the LLVM runtime, which first looks for
the symbol in the C library and Pure's runtime library (or the interpreter
executable, if the interpreter was linked statically). Thus all C library and
Pure runtime functions are readily available in Pure programs. Other functions
can be provided by adding them to the runtime, or by linking them into the
runtime or the interpreter executable. Better yet, you can just ``dlopen''
shared libraries at runtime with a special form of the
.B using
clause:
.sp
.nf
\fBusing\fP "lib:\fIlibname\fR[.\fIext\fP]";
.fi
.sp
For instance, if you want to call the functions from library `libxyz' directly
from Pure:
.sp
.nf
\fBusing\fP "lib:libxyz";
.fi
.sp
After this declaration the functions from the given library will be ready to
be imported into your Pure program by means of corresponding
.B extern
declarations.
.PP
Shared libraries opened with \fBusing\fP clauses are searched for in the same
way as source scripts (see section \fIDECLARATIONS\fP above), using the
.B -L
option and the
.B PURE_LIBRARY
environment variable in place of
.B -I
and
.BR PURE_INCLUDE .
If the library isn't found by these means, the interpreter will also consider
other platform-specific locations searched by the dynamic linker, such as the
system library directories and
.B LD_LIBRARY_PATH
on Linux. The necessary filename suffix (e.g., \fB.so\fP on Linux or
\fB.dll\fP on Windows) will be supplied automatically when needed. Of course
you can also specify a full pathname for the library if you prefer that. If a
library file cannot be found, or if an
.B extern
declaration names a function symbol which cannot be resolved, an appropriate
error message is printed.
.SH STANDARD LIBRARY
Pure comes with a collection of Pure library modules, which includes the
standard prelude (loaded automatically at startup time) and some other modules
which can be loaded explicitly with a
.B using
clause. The prelude offers the necessary functions to work with the built-in
types (including arithmetic and logical operations) and to do most kind of
list processing you can find in ML- and Haskell-like languages. It also
provides a collection of basic string and matrix operations. Please refer to
the
.B prelude.pure
file (as well as the modules included there, specifically
.BR primitives.pure ,
.B matrices.pure
and
.BR strings.pure )
for details on the provided operations. Here is a very brief summary of some
of the prelude operations which, besides the usual arithmetic and logical
operators, are probably used most frequently:
.TP
x+y
This is also used to denote list and string concatenation.
.TP
x:y
This is the list-consing operation. x becomes the head of the list, y its
tail.  As `:' is a constructor symbol, you can use it in patterns on the left
hand side of rewriting rules.
.TP
x..y
Constructs arithmetic sequences. x:y..z can be used to denote sequences with
arbitrary stepsize y-x. Infinite sequences can be constructed using an
infinite bound (i.e., inf or -inf). E.g., 1:3..inf denotes the stream of all
positive odd (machine) integers.
.TP
x,y
This is the pair constructor, used to create tuples of arbitrary sizes. Tuples
provide an alternative way to represent aggregate values in Pure. In
difference to lists, tuples are always ``flat'', so that (x,y),z and x,(y,z)
denote the same triple x,y,z. (This is explained in more detail in the \fIPURE
OVERVIEW\fP section.)
.TP
#x
The size (number of elements) of the list, tuple, matrix or string x. In
addition, dim x yields the dimensions (number of rows and columns) of a
matrix.
.TP
x'
The transpose of a matrix.
.TP
x!y
This is Pure's indexing operation, which applies to lists, tuples, matrices
and strings. Note that all indices in Pure are zero-based, thus x!0 and
x!(#x-1) are the first and last element of x. In the case of matrices, the
subscript may also be a pair of row and column indices, such as x!(1,2).
.TP
x!!ys
This is the ``slicing'' operation, which returns the list, tuple, matrix or
string of all x!y while y runs through the (list or matrix) ys.  Thus, e.g.,
x!!(i..j) returns all the elements between i and j (inclusive). Indices which
fall outside the valid index range are quietly discarded. The index range ys
may contain any number of indices (also duplicates), in any order. Thus
x![0|i=1..n] returns the first element of x n times, and, if ys is a
permutation of the range 0..#x-1, then x!!ys yields the corresponding
permutation of the elements of x. In the case of matrices the index range may
also contain two-dimensional subscripts, or the index range itself may be
specified as a pair of row/column index lists such as x!!(i..j,k..l).
.PP
The prelude also offers support operations for the implementation of list and
matrix comprehensions, as well as the customary list operations like head,
tail, drop, take, filter, map, foldl, foldr, scanl, scanr, zip, unzip, etc.,
which make list programming so much fun in modern FPLs. In Pure, these also
work on strings as well as matrices, although, for reasons of efficiency,
these data structures are internally represented as different kinds of array
data structures.
.PP
Besides the prelude, Pure's standard library also comprises a growing number
of additional library modules which we can only mention in passing here. In
particular, the
.B math.pure
module provides additional mathematical functions as well as Pure's complex
and rational number data types. Common container data structures like sets and
dictionaries are implemented in the
.B set.pure
and
.B dict.pure
modules, among others. Moreover, the (beginnings of a) system interface can be
found in the
.B system.pure
module. In particular, this module also provides operations to do basic
C-style I/O, including printf and scanf. More stuff will likely be provided in
future releases.
.SH INTERACTIVE USAGE
In interactive mode, the interpreter reads definitions and expressions and
processes them as usual. You can use the 
.B -i
option to force interactive mode when invoking the interpreter with some
script files. Additional scripts can be loaded interactively using either a
.B using
declaration or the interactive
.B run
command (see the description of the
.B run
command below for the differences between these). Or you can just start typing
away, entering your own definitions and expressions to be evaluated.
.PP
The input language is just the same as for source scripts, and hence
individual definitions and expressions \fImust\fP be terminated with a
semicolon before they are processed. For instance, here is a simple
interaction which defines the factorial and then uses that definition in some
evaluations. Input lines begin with ``>'', which is the interpreter's default
command prompt:
.sp
.nf
> fact 1 = 1;
> fact n = n*fact (n-1) \fBif\fP n>1;
> \fBlet\fP x = fact 10; x;
3628800
> map fact (1..10);
[1,2,6,24,120,720,5040,40320,362880,3628800]
.fi
.PP
As indicated, in interactive mode the normal forms of toplevel expressions are
printed after each expression is entered. We also call this the
.I read-eval-print
loop. Normal form expressions are usually printed in the same form as you'd
enter them. However, there are a few special kinds of objects like anonymous
closures, thunks (``lazy'' values to be evaluated when needed) and pointers
which don't have a textual representation in the Pure syntax and will be
printed in the format \fB#<\fP\fIobject description\fP\fB>\fP by default. It
is also possible to override the print representation of any kind of
expression by means of the
.B __show__
function, see the \fICAVEATS AND NOTES\fP section for details.
.SS Interactive Commands
When running interactively, the interpreter accepts a number of special
commands useful for interactive purposes. Here is a quick rundown of the
currently supported operations:
.TP
\fB!\fP \fIcommand\fP
Shell escape.
.TP
\fBcd\fP \fIdir\fP
Change the current working dir.
.TP
\fBclear\fP [\fIoption\fP ...] [\fIsymbol\fP ...]
Purge the definitions of the given symbols (functions, macros, constants or
global variables). When invoked without any arguments,
.B clear
purges
.I all
definitions at the current interactive ``level'' (after confirmation) and
returns you to the previous level, if any. (It might be a good idea to first
check your current definitions with \fBshow\fP or back them up with \fBdump\fP
before you do that.) The desired level can be specified with the
.B -t
option. See the description of the
.B save
command and \fIDefinition Levels\fP below for further details. A description
of the common options accepted by the
.BR clear ,
.B dump
and
.B show
commands can be found in \fISpecifying Symbol Selections\fP below.
.TP
\fBdump\fP [-n \fIfilename\fP] [\fIoption\fP ...] [\fIsymbol\fP ...]
Dump a snapshot of the current function, macro, constant and variable
definitions in Pure syntax to a text file. This works similar to the
.B show
command (see below), but writes the definitions to a file. The default output
file is
.B .pure
in the current directory, which is then reloaded automatically the next time
the interpreter starts up in interactive mode in the same directory. This
provides a quick-and-dirty way to save an interactive session and have it
restored later, but note that this isn't perfect yet. In particular,
declarations of
.B extern
symbols won't be saved unless they're specified explicitly, and some objects
like closures, thunks and pointers don't have a textual representation from
which they could be reconstructed. To handle these, you'll probably have to
prepare a corresponding
.B .purerc
file yourself, see \fIStartup Files\fP below.
.sp
A different filename can be specified with the
.B -n
option, which expects the name of the script to be written in the next
argument, e.g: \fBdump -n myscript.pure\fP. You can then edit that file and
use it as a starting point for an ordinary script or a
.B .purerc
file, or you can just run the file with the
.B run
command (see below) to restore the definitions in a subsequent interpreter
session.
.TP
\fBhelp\fP [\fIargs\fP]
Display the
.BR pure (1)
manpage, or invoke
.BR man (1)
with the given arguments.
.TP
\fBls\fP [\fIargs\fP]
List files (shell \fBls\fP(1) command).
.TP
.B override
Enter ``override'' mode. This allows you to add equations ``above'' existing
definitions in the source script, possibly overriding existing equations. See
\fIDefinition Levels\fP below for details.
.TP
.B pwd
Print the current working dir (shell \fBpwd\fP(1) command).
.TP
.B quit
Exits the interpreter.
.TP
\fBrun\fP \fIscript\fP
Loads the given script file and adds its definitions to the current
environment. This works more or less like a
.B using
clause, but only searches for the script in the current directory and places
the definitions in the script at the current temporary level, so that
.B clear
can be used to remove them again. In particular, this makes it possible to
quickly reload a script without exiting the interpreter, by issuing the
.B clear
command followed by
.BR run .
(This works best if you start out from a clean environment, with no scripts
loaded on the command line.)
.TP
.B save
Begin a new level of temporary definitions. A subsequent
.B clear
command (see above) will purge the definitions made since the most recent
.B save
command. See \fIDefinition Levels\fP below for details.
.TP
\fBshow\fP [\fIoption\fP ...] [\fIsymbol\fP ...]
Show the definitions of symbols in various formats. See \fIThe show Command\fP
below for details. A description of the common options accepted by the
.BR clear ,
.B dump
and
.B show
commands can be found in \fISpecifying Symbol Selections\fP below.
.TP
\fBstats\fP [on|off]
Enables (default) or disables ``stats'' mode, in which various statistics are
printed after an expression has been evaluated. Currently, this just prints
the cpu time in seconds for each evaluation, but in the future additional
profiling information may be provided.
.TP
.B underride
Exits ``override'' mode. This returns you to the normal mode of operation,
where new equations are added `below'' previous rules of an existing function.
See \fIDefinition Levels\fP below for details.
.PP
Note that these special commands are only recognized at the beginning of the
interactive command line (they are not reserved keywords of the Pure
language). Thus it's possible to ``escape'' identifiers looking like commands
by entering a space at the beginning of the line. However, the compiler also
warns you about identifiers which might be mistaken as command names, so that
you can easily avoid this kind of problem.
.PP
Some of the more advanced commands and options for power users are discussed
in more detail in the following subsections.
.SS Specifying Symbol Selections
The
.BR clear ,
.B dump
and
.B show
commands all accept the following options for specifying a subset of symbols
and definitions on which to operate. Options may be combined, thus, e.g.,
\fBshow -mft\fP is the same as \fBshow -m -f -t\fP. Some options specify
optional numeric parameters; these must follow immediately behind the option
character if present, as in
.BR -t0 .
.TP
.B -c
Selects defined constants.
.TP
.B -f
Selects defined functions.
.TP
.B -g
Indicates that the following symbols are actually shell glob patterns and that
all matching symbols should be selected.
.TP
.B -m
Select defined macros.
.TP
\fB-p\fP[\fIflag\fP]
Select only private symbols if \fIflag\fP is nonzero (the default), otherwise
(\fIflag\fP is zero) select only public symbols. If this option is omitted
then both private and public symbols are selected.
.TP
\fB-t\fP[\fIlevel\fP]
Select symbols and definitions at the given ``level'' of definitions and
above. This is described in more detail below. Briefly, the executing program
and all imported modules (including the prelude) are at level 0, while
``temporary'' definitions made interactively in the interpreter are at level 1
and above. Thus a \fIlevel\fP of 1 restricts the selection to all temporary
definitions, whereas 0 indicates \fIall\fP definitions (i.e., everything,
including the prelude). If \fIlevel\fP is omitted, it defaults to the current
definitions level.
.TP
.B -v
Select defined variables.
.PP
In addition, the
.B -h
option prints a short help message describing all available options of the
command at hand.
.PP
If none of the
.BR -c ,
.BR -f ,
.B -m
and
.B -v
options are specified, then all kinds of symbols (constants, functions, macros
and variables) are selected, otherwise only the specified categories will be
considered.
.PP
A reasonable default is used if the \fB-t\fP option is omitted. By default, if
no symbols are specified, only temporary definitions are considered, which
corresponds to
.BR -t1 .
Otherwise the command applies to
.I all
corresponding definitions, no matter whether they belong to the executing
program, the prelude, or some temporary level, which has the same effect as
.BR -t0 .
This default choice can be overridden by specifying the desired level
explicitly.
.PP
As a special case, just
.B clear
(without any other options or symbol arguments) always backs out to the
.I previous
definitions level (instead of level #1). This is inconsistent with the rules
set out above, but is implemented this way for convenience and backward
compatibility. Thus, if you really want to delete
.I all
your temporary definitions, use
.B clear -t1
instead. When used in this way, the
.B clear
command will only remove temporary definitions; if you need to remove
definitions at level #0, you must specify those symbols explicitly.
.PP
Note that
.B clear -g *
will have pretty much the same disastrous consequences as the Unix command
\fBrm -rf *\fP, so don't do that. Also note that a macro or function symbol
may well have defining equations at different levels, in which case a command
like \fBclear -t\fP\fIn\fP \fBfoo\fP might only affect some part of foo's
definition. The
.B dump
and
.B show
commands work analogously (albeit less destructively). See \fIDefinition
Levels\fP below for some examples.
.SS The show Command
The
.B show
command can be used to obtain information about defined symbols in various
formats. Besides the common selection options discussed above, this command
recognizes the following additional options for specifying the content to be
listed and the format to use.
.TP
.B -a
Disassembles pattern matching automata. Works like the
.B -v4
option of the interpreter.
.TP
.B -d
Disassembles LLVM IR, showing the generated LLVM assembler code of a
function. Works like the
.B -v8
option of the interpreter.
.TP
.B -e
Annotate printed definitions with lexical environment information (de Bruijn
indices, subterm paths). Works like the
.B -v2
option of the interpreter.
.TP
.B -l
Long format, prints definitions along with the summary symbol information.
This implies \fB-s\fP.
.TP
.B -s
Summary format, print just summary information about listed symbols.
.PP
Symbols are always listed in lexicographic order. Note that some of the
options (in particular,
.B -a
and
.BR -d )
may produce excessive amounts of information. By setting the
.B PURE_MORE
environment variable accordingly, you can specify a shell command to be used
for paging, usually
.BR more (1)
or
.BR less (1).
.PP
For instance, to list all temporary definitions made in an interactive
session, simply say:
.sp
.nf
> \fBshow\fP
.fi
.PP
You can also list a specific symbol, no matter whether it comes from the
interactive command line, the executing script or the prelude:
.sp
.nf
> \fBshow\fP foldl
foldl f a x::matrix = foldl f a (list x);
foldl f a s::string = foldl f a (chars s);
foldl f a [] = a;
foldl f a (x:xs) = foldl f (f a x) xs;
.fi
.PP
Wildcards can be used with the
.B -g
option, which is useful if you want to print an entire family of related
functions, e.g.:
.sp
.nf
> \fBshow\fP -g foldl*
foldl f a x::matrix = foldl f a (list x);
foldl f a s::string = foldl f a (chars s);
foldl f a [] = a;
foldl f a (x:xs) = foldl f (f a x) xs;
foldl1 f x::matrix = foldl1 f (list x);
foldl1 f s::string = foldl1 f (chars s);
foldl1 f (x:xs) = foldl f x xs;
.fi
.PP
Or you can just specify multiple symbols as follows (this also works with
multiple glob patterns when you add the
.B -g
option):
.sp
.nf
> \fBshow\fP min max
max x y = if x>=y then x else y;
min x y = if x<=y then x else y;
.fi
.PP
You can also select symbols by category. E.g., the following command shows
summary information about all the variable symbols along with their current
values (using the ``long format''):
.sp
.nf
> \fBshow\fP -lvg *
argc         var  argc = 0;
argv         var  argv = [];
gsl_version  var  gsl_version = "1.9";
sysinfo      var  sysinfo = "i686-pc-linux-gnu";
version      var  version = "@version@";
5 variables
.fi
.PP
Or you can list just private symbols of the namespace `foo', as follows:
.sp
.nf
> \fBshow\fP -pg foo::*
.fi
.PP
The following command will list each and every symbol that's currently defined
(instead of \fB-g *\fP you can also use the \fB-t0\fP option):
.sp
.nf
> \fBshow\fP -g *
.fi
.PP
This usually produces a lot of output and is rarely needed, unless you'd like
to browse through an entire program including all library imports. (In that
case you might consider to use the
.B dump
command instead, which writes the definitions to a file which can then be
loaded into a text editor for easier viewing. This may occasionally be useful
for debugging purposes.)
.PP
Finally, there are two alternate forms of the
.B show
command: `\fBshow\fP namespace' which lists the current and search namespaces,
and `\fBshow\fP namespaces' which lists all declared namespaces. These come in
handy if you have forgotten what namespaces are currently active and which
other namespaces are available in your program. For instance:
.sp
.nf
> \fBshow\fP namespace
> \fBshow\fP namespaces
\fBnamespace\fP C;
\fBnamespace\fP matrix;
> \fBusing\fP \fBnamespace\fP C;
> \fBnamespace\fP my;
> \fBshow\fP namespace
\fBnamespace\fP my;
\fBusing\fP \fBnamespace\fP C;
.fi
.SS Definition Levels
To help with incremental development, the interpreter offers some facilities
to manipulate the current set of definitions interactively. To these ends,
definitions are organized into different subsets called \fIlevels\fP. As
already mentioned, the prelude, as well as other source programs specified
when invoking the interpreter, are always at level 0, while the interactive
environment starts at level 1.
.PP
Each \fBsave\fP command introduces a new temporary level, and each subsequent
\fBclear\fP command (without any arguments) ``pops'' the definitions on the
current level and returns you to the previous one (if any). This gives you a
``stack'' of temporary environments which enables you to ``plug and play'' in
a (more or less) safe fashion, without affecting the rest of your program. For
all practical purposes, this stack is unlimited, so that you can create as
many levels as you like. Example:
.sp
.nf
> foo (x:xs) = x+foo xs;
> foo [] = 0;
> \fBshow\fP
foo (x:xs) = x+foo xs;
foo [] = 0;
> foo (1..10);
55
> \fBclear\fP
This will clear all temporary definitions at level #1.
Continue (y/n)? \fBy\fP
> \fBshow\fP
> foo (1..10);
foo [1,2,3,4,5,6,7,8,9,10]
.fi
.PP
We've seen already that normally, if you enter a sequence of equations, they
will be recorded in the order in which they were written. However, it is also
possible to override definitions in lower levels with the
.B override
command:
.sp
.nf
> foo (x:xs) = x+foo xs;
> foo [] = 0;
> \fBshow\fP
foo (x:xs) = x+foo xs;
foo [] = 0;
> foo (1..10);
55
> \fBsave\fP
save: now at temporary definitions level #2
> \fBoverride\fP
> foo (x:xs) = x*foo xs;
> \fBshow\fP
foo (x:xs) = x*foo xs;
foo (x:xs) = x+foo xs;
foo [] = 0;
> foo (1..10);
warning: rule never reduced: foo (x:xs) = x+foo xs;
0
.fi
.PP
Note that the equation `foo (x:xs) = x*foo xs;' was inserted before the
previous `foo (x:xs) = x+foo xs;' rule, which is at level #1. (The latter
equation is now ``shadowed'' by the rule we just entered, hence the compiler
warns us that this rule can't be reduced any more.)
.PP
Even in override mode, new definitions will be added \fIafter\fP other
definitions at the \fIcurrent\fP level. This allows us to just continue adding
more high-priority definitions overriding lower-priority ones:
.sp
.nf
> foo [] = 1;
> \fBshow\fP
foo (x:xs) = x*foo xs;
foo [] = 1;
foo (x:xs) = x+foo xs;
foo [] = 0;
> foo (1..10);
warning: rule never reduced: foo (x:xs) = x+foo xs;
warning: rule never reduced: foo [] = 0;
3628800
.fi
.PP
Again, the new equation was inserted \fIabove\fP the existing lower-priority
rules, but \fIbelow\fP our previous `foo (x:xs) = x*foo xs;' equation entered
at the same level. As you can see, we have now effectively replaced our
original definition of `foo' with a version that calculates list products
instead of sums, but of course we can easily go back one level to restore the
previous definition:
.sp
.nf
> \fBclear\fP
This will clear all temporary definitions at level #2.
Continue (y/n)? \fBy\fP
clear: now at temporary definitions level #1
clear: override mode is on
> \fBshow\fP
foo (x:xs) = x+foo xs;
foo [] = 0;
> foo (1..10);
55
.fi
.PP
Note that
.B clear
reminded us that override mode is still enabled (\fBsave\fP will do the same
if override mode is on while pushing a new definitions level). To turn it off
again, use the
.B underride
command. This will revert to the normal behaviour of adding new equations
below existing ones:
.sp
.nf
> \fBunderride\fP
.fi
.PP
Finally, it's also possible to use
.B clear
to back out multiple levels at once, if you specify the target level to be
cleared with the
.B -t
option. For instance:
.sp
.nf
> \fBsave\fP
save: now at temporary definitions level #2
> \fBlet\fP bar = 99;
> \fBshow\fP
let bar = 99;
foo (x:xs) = x+foo xs;
foo [] = 0;
> \fBclear\fP -t1 // this scraps \fIall\fP our scribblings!
This will clear all temporary definitions at level #1 and above.
Continue (y/n)? \fBy\fP
clear: now at temporary definitions level #1
> \fBshow\fP
>
.fi
.SS Startup Files
In interactive mode, the interpreter also runs some additional scripts at
startup, after loading the prelude and the scripts specified on the command
line. This lets you tailor the interactive environment to your liking.
.PP
The interpreter first looks for a
.B .purerc
file in the user's home directory (as given by the
.B HOME
environment variable) and then for a
.B .purerc
file in the current working directory. These are just ordinary Pure scripts
which may contain any additional definitions that you need. The
.B .purerc
file in the home directory is for global definitions which should always be
available when running interactively, while the
.B .purerc
file in the current directory can be used for project-specific
definitions.
.PP
Finally, you can also have a
.B .pure
initialization file in the current directory, which is created by the
.B dump
command (see above) and is loaded after the
.B .purerc
files if it is present.
.PP
The interpreter processes all these files in the same way as with the
.B run
command (see above). When invoking the interpreter, you can specify the
.B --norc
option on the command line if you wish to skip these initializations.
.SH CAVEATS AND NOTES
This section is a grab bag of casual remarks, useful tips and tricks, and
information on common pitfalls, quirks and limitations of the current
implementation and how to deal with them.
.SS Purity
People keep asking me what's so ``pure'' about Pure. The long and apologetic
answer is that at its core, Pure is in fact purely algebraic and purely
functional. Pure doesn't get in your way if you want to call external
operations with side effects (it does allow you to call any C function after
all), but with a few exceptions the standard library operations are free of
those. Just stay away from operations marked ``IMPURE'' in the library sources
(most notably, eval, catch/throw, references, sentries and direct pointer
manipulations) and avoid the system module, then your program will behave
according to the semantics of term rewriting.
.PP
The short answer is that I simply liked the name, and there wasn't any
programming language named ``Pure'' yet (quite a feat nowadays), so there's
one now. :)
.SS Backward Compatibility
Pure 0.7 introduced built-in matrix structures, which called for some minor
changes in the syntax of comprehensions and arithmetic
sequences. Specifically, the template expression and generator/filter clauses
of a comprehension are now separated with `|' instead of `;'. Moreover,
arithmetic sequences with arbitrary stepsize are now written x:y..z instead of
x,y..z, and the `..' operator now has a higher precedence than the `,'
operator. This makes writing matrix slices like x!!(i..j,k..l) much more
convenient.
.PP
In Pure 0.13 the naming of the logical and bitwise operations was changed, so
that these are now called ~, &&, || and not/and/or, respectively. (Previously,
~ was used for bitwise, `not' for logical negation, which was rather
inconsistent, albeit compatible with the naming of the `not' operation in
Haskell and ML.) Also, to stay in line with this naming scheme, inequality was
renamed to ~= (previously !=).
.PP
Pure 0.14 introduced the namespaces feature. Consequently, the scope of
private symbols is now confined to a namespace rather than a source module;
scripts making use of private symbols need to be adapted accordingly. Also
note that syntax like `foo::int' may now also denote a qualified symbol rather
than a tagged variable, if `foo' has been declared as a namespace. You can
work around such ambiguities by renaming the variable, or by placing spaces
around the `::' delimiter (these aren't permitted in a qualified symbol, so
the construct `foo :: int' is always interpreted as a tagged variable, no
matter whether `foo' is also a valid namespace).
.SS Error Recovery
The parser uses a fairly simplistic panic mode error recovery which tries to
catch syntax errors at the toplevel only. This seems to work reasonably well,
but might catch some errors much too late. Unfortunately, Pure's terseness
makes it rather difficult to design a better scheme. As a remedy, the parser
accepts an empty definition (just `;' by itself) at the toplevel only. Thus,
in interactive usage, if the parser seems to eat away your input without doing
anything, entering an extra semicolon or two should break the spell, putting
you back at the toplevel where you can start typing the definition again.
.SS Debugging
There's no symbolic debugger yet. So
.BR printf (3)
(available in the
.B system
standard library module) should be your friend. ;-) Also, have a look at the
\fIMACROS\fP section which discusses a little helper macro to trace global
function calls in a semi-automatic fashion.
.SS The __show__ Function
As of Pure 0.6, the interpreter provides a ``hook'' to override the print
representations of expressions at runtime by means of the
.B __show__
function, which works in a fashion similar to Haskell's show function. This
feature is still a bit experimental, but seems to work reasonably well for the
purposes for which it is intended.
.PP
.B __show__
is just an ordinary Pure function expected to return a string with the desired
custom representation of a normal form value given as the function's single
argument. This function is not defined by default, so you are free to add any
rules that you want. The interpreter prints the strings returned by __show__
just as they are. It will
.I not
check whether they conform to Pure syntax and/or semantics, or modify them in
any way.
.PP
Custom print representations are most useful for interactive purposes, if
you're not happy with the default print syntax of some kinds of objects. One
particularly useful application of __show__ is to change the format of numeric
values. Here are some examples:
.sp
.nf
> \fBusing\fP system;
> __show__ x::double = sprintf "%0.6f" x;
> 1/7;
0.142857
> __show__ x::int = sprintf "0x%0x" x;
> 1786;
0x6fa
> \fBusing\fP math;
> __show__ (x::double+:y::double) = sprintf "%0.6f+%0.6fi" (x,y);
> cis (-pi/2);
0.000000+-1.000000i
.fi
.PP
The prelude function
.BR str ,
which returns the print representation of any Pure expression, calls __show__
as well:
.sp
.nf
> str (1/7);
"0.142857"
.fi
.PP
Conversely, you can call the str function from __show__, but in this case it
always returns the default representation of an expression. This prevents the
expression printer from going recursive, and allows you to define your custom
representation in terms of the default one. E.g., the following rule removes
the `L' suffixes from bigint values:
.sp
.nf
> __show__ x::bigint = init (str x);
> fact n = foldl (*) 1L (1..n);
> fact 30;
265252859812191058636308480000000
.fi
.PP
Of course, your definition of __show__ can also call __show__ itself
recursively to determine the custom representation of an object.
.PP
One case which needs special consideration are thunks (futures). The printer
will never use __show__ for those, to prevent them from being forced
inadvertently. In fact, you
.I can
use __show__ to define custom representations for thunks, but only in the
context of a rule for other kinds of objects, such as lists. For instance:
.sp
.nf
> \fBnullary\fP ...;
> __show__ (x:xs) = str (x:...) \fBif\fP thunkp xs;
> 1:2:(3..inf);
1:2:3:...
.fi
.PP
Another case which needs special consideration are numeric matrices. For
efficiency, the expression printer will always use the default representation
for these, unless you override the representation of the matrix as a
whole. E.g., the following rule for double matrices mimics Octave's default
output format (for the sake of simplicity, this isn't perfect, but you get the
idea):
.sp
.nf
> __show__ x::matrix =
>   strcat [printd j (x!(i,j))|i=0..n-1; j=0..m-1] + "\en"
> \fBwith\fP printd 0 = sprintf "\en%10.5f"; printd _ = sprintf "%10.5f" \fBend\fP
> \fBwhen\fP n,m = dim x \fBend\fP \fBif\fP dmatrixp x;
> {1.0,1/2;1/3,4.0};

   1.00000   0.50000
   0.33333   4.00000
.fi
.PP
Finally, by just purging the definition of the __show__ function you can
easily go back to the standard print syntax:
.sp
.nf
> \fBclear\fP __show__
> 1/7; 1786; cis (-pi/2);
0.142857142857143
1786
6.12303176911189e-17+:-1.0
.fi
.PP
Note that if you have a set of definitions for the __show__ function which
should always be loaded at startup, you can put them into the interpreter's
interactive startup files, see \fIINTERACTIVE USAGE\fP.
.SS ``As'' Patterns
In the current implementation, ``as'' patterns cannot be placed on the
``spine'' of a function definition. Thus rules like the following, which have
the pattern somewhere in the head of the left-hand side, will all provoke an
error message from the compiler:
.sp
.nf
a@foo x y   = a,x,y;
a@(foo x) y = a,x,y;
a@(foo x y) = a,x,y;
.fi
.PP
This is because the spine of a function application is not available when the
function is called at runtime. ``As'' patterns in pattern bindings
(\fBcase\fP, \fBwhen\fP) are not affected by this restriction since the entire
value to be matched is available at runtime. For instance:
.sp
.nf
> \fBcase\fP bar 99 \fBof\fP y@(bar x) = y,x+1; \fBend\fP;
bar 99,100
.fi
.SS Head = Function
``As'' patterns are also a useful device if you need to manipulate function
applications in a generic way. Note that the ``head = function'' rule means
that the head symbol f of an application f x1 ... xn occurring on (or inside)
the left-hand side of an equation, variable binding, or pattern-matching
lambda expression, is always interpreted as a literal function symbol (not a
variable). This implies that you cannot match the ``function'' component of an
application against a variable, at least not directly. An anonymous ``as''
pattern like f@_ does the trick, however, since the anonymous variable is
always recognized, even if it occurs as the head symbol of a function
application. Here's a little example which demonstrates how you can convert a
function application to a list containing the function and all arguments:
.sp
.nf
> foo x = a [] x \fBwith\fP a xs (x@_ y) = a (y:xs) x; a xs x = x:xs \fBend\fP;
> foo (a b c d);
[a,b,c,d]
.fi
.PP
This may seem a little awkward, but as a matter of fact the ``head =
function'' rule is quite useful since it covers the common cases without
forcing the programmer to declare ``constructor'' symbols (except nullary
symbols). On the other hand, generic rules operating on arbitrary function
applications are not all that common, so having to ``escape'' a variable using
the anonymous ``as'' pattern trick is a small price to pay for that
convenience.
.PP
Sometimes you may also run into the complementary problem, i.e., to match a
function argument against a given function. Consider this code fragment:
.sp
.nf
foo x = x+1;
foop f = \fBcase\fP f \fBof\fP foo = 1; _ = 0 \fBend\fP;
.fi
.PP
You might expect `foop' to return true for `foo', and false on all other
values. Better think again, because in reality `foop' will
.I always
return true! In fact, the Pure compiler will warn you about the second rule
of the
.B case
expression not being used at all:
.sp
.nf
> foop 99;
warning: rule never reduced: _ = 0;
1
.fi
.PP
This happens because a non-nullary symbol on the left-hand side of a rule,
which is not the head symbol of a function application, is always considered
to be a variable, even if that symbol is defined as a global function
elsewhere. So `foo' isn't a literal name in the above
.B case
expression, it's a variable! (As a matter of fact, this is rather useful,
since otherwise a rule like `f g = g+1' would suddenly change meaning if you
happen to add a definition like `g x = x-1' somewhere else in your program,
which certainly isn't desirable.)
.PP
A possible workaround is to ``escape'' the function symbol using an empty
namespace qualifier:
.sp
.nf
foop f = \fBcase\fP f \fBof\fP ::foo = 1; _ = 0 \fBend\fP;
.fi
.PP
This trick works in \fBcase\fP expressions and function definitions, but fails
in circumstances in which qualified variable symbols are permitted (i.e., in
variable and constant definitions). A better solution is to employ the
syntactic equality operator `===' defined in the prelude to match the target
value against the function symbol. This allows you to define the `foop'
predicate as follows:
.sp
.nf
> foop f = f===foo;
> foop foo, foop 99;
1,0
.fi
.PP
Another way to deal with the situation would be to just declare `foo' as a
.B nullary
symbol. However, this makes the `foo' symbol ``precious'', i.e., after such a
declaration it cannot be used as a local variable anymore. It's usually a good
idea to avoid that kind of thing, at least for generic symbols, so the above
solution is preferred in this case.
.SS Namespaces and Implicit Declarations
A common pitfall is the implicit declaration of unqualified symbols in
conjunction with the
.B namespace
declaration. For instance, it is tempting to write
.sp
.nf
\fBnamespace\fP bar;
foo x = x+1;
.fi
.sp
and expect `foo' to become a member of the `bar' namespace. But, assuming that
`foo' is not already declared or defined elsewhere, it will actually become a
member of the
.I default
namespace instead. This is necessary because in Pure it is impossible to
distinguish local variables from unqualified function symbols at the lexical
level, and thus
.I all
undeclared and unqualified identifiers are implicitly declared in the default
namespace. Thus, if you really want the `foo' symbol to become a member of the
`bar' namespace, you
.I must
either declare it explicitly or use a qualfified identifier. That is, either
.sp
.nf
\fBnamespace\fP bar;
bar::foo x = x+1;
.fi
.sp
or
.sp
.nf
\fBnamespace\fP bar;
\fBpublic\fP foo;
foo x = x+1;
.fi
.sp
will tell the compiler about the desired namespace of the symbol.
.SS With or when?
Another common source of confusion is that Pure provides two different
constructs to bind local function and variable symbols, respectively. This
distinction is necessary because Pure does not segregate defined functions and
constructors, and thus there is no magic to figure out whether an equation
like `foo x = y' by itself is meant as a definition of a function foo with
formal parameter x and return value y, or a definition binding the local
variable x by matching the constructor pattern foo x against the value y. The
.B with
construct does the former,
.B when
the latter.
.PP
Another speciality is that
.B with
and
.B when
clauses are tacked on to the end of the expression they belong to, which
mimics mathematical language but may be unfamilar if you're more accustomed to
programming languages from the Algol/Pascal/C family. If you want to figure
out what is actually going on there, it's usually best to read nested scopes
``in reverse'' (proceeding from the rightmost/outermost to the
leftmost/innermost clause).
.SS Numeric Calculations
If possible, you should decorate numeric variables on the left-hand sides of
function definitions with the appropriate type tags, like
.B ::int
or
.BR ::double .
This often helps the compiler to generate better code and makes your programs
run faster. The `|' syntax makes it easy to add the necessary specializations
of existing rules to your program. E.g., taking the polymorphic implementation
of the factorial as an example, you only have to add a left-hand side with the
appropriate type tag to make that definition go as fast as possible for the
special case of machine integers:
.sp
.nf
fact n::int    |
fact n         = n*fact(n-1) \fBif\fP n>0;
               = 1 \fBotherwise\fP;
.fi
.PP
(This obviously becomes unwieldy if you have to deal with several numeric
arguments of different types, however, so in this case it is usually better to
just use a polymorphic rule.)
.PP
Also note that
.B int
(the machine integers) and
.B bigint
(the GMP ``big'' integers) are really different kinds of objects, and thus if
you want to define a function operating on both kinds of integers, you'll also
have to provide equations for both. This also applies to equations matching
against constant values of these types; in particular, a small integer
constant like `0' only matches machine integers, not bigints; for the latter
you'll have to use the ``big L'' notation `0L'.
.SS Constant Definitions
When definining a function in terms of constant values which have to be
computed beforehand, it's usually better to use a
.B const
definition (rather than defining a variable or a parameterless function or
macro) for that purpose, since this will often allow the compiler to generate
better code using constant folding and similar techniques. Example:
.sp
.nf
> \fBextern\fP double atan(double);
> \fBconst\fP pi = 4*atan 1.0;
> foo x = 2*pi*x;
> \fBshow\fP foo
foo x = 2*3.14159265358979*x;
.fi
.PP
(If you take a look at the disassembled code for this function, you will find
that the value 2*3.14159265358979 = 6.28318530717959 has actually been
computed at compile time.)
.PP
Note that constant definitions differ from parameterless macros in that the
right-hand side of the definition is in fact evaluated at definition
time. E.g., compare the above with the following macro definition:
.sp
.nf
> \fBclear\fP pi foo
> \fBdef\fP pi = 4*atan 1.0;
> foo x = 2*pi*x;
> \fBshow\fP foo
foo x = 2*(4*atan 1.0)*x;
.fi
.PP
The LLVM backend also eliminates dead code automagically, which enables you to
employ a constant computed at runtime to configure your code for different
environments, without any runtime penalties:
.sp
.nf
\fBconst\fP win = index sysinfo "mingw32" >= 0;
check boy = bad boy \fBif\fP win;
          = good boy \fBotherwise\fP;
.fi
.PP
In this case the code for one of the branches of `check' will be completely
eliminated, depending on the outcome of the configuration check.
.PP
On the other hand, constant definitions are somewhat limited in scope compared
to variable definitions, since the bound value must be usable at compile time,
so that it can be substituted into other definitions. Thus, while there is no
\fIa priori\fP restriction on the computations you can perform to obtain the
value of the constant, the value must not be a pointer object (other than the
null pointer), or an anonymous closure (which also rules out local functions,
because these cannot be referred to by their names at the toplevel), or an
aggregate value containing any such values.
.PP
Constants also differ from variables in that they cannot be redefined (that's
their purpose after all) and will only take effect on subsequent
definitions. E.g.:
.sp
.nf
> \fBconst\fP c = 2;
> foo x = c*x;
> \fBshow\fP foo
foo x = 2*x;
> foo 99;
198
> \fBconst\fP c = 3;
<stdin>, line 5: symbol 'c' is already defined as a constant
.fi
.PP
Well, in fact this not the full truth because in interactive mode it \fIis\fP
possible to redefine constants after all, if the old definition is first
purged with the \fBclear\fP command. However, this won't affect any other
existing definitions:
.sp
.nf
> \fBclear\fP c
> \fBconst\fP c = 3;
> bar x = c*x;
> \fBshow\fP foo bar
foo x = 2*x;
bar x = 3*x;
.fi
.PP
(You'll also have to purge any existing definition of a variable if you want
to redefine it as a constant, or vice versa, since Pure won't let you redefine
an existing constant or variable as a different kind of symbol. The same also
holds if a symbol is currently defined as a function or a macro.)
.PP
Finally, note that in difference to
.B nullary
symbols, by default
.B const
symbols can
.I not
be used on the left-hand side of a rule. E.g., the following will not work as
expected:
.sp
.nf
> const zero = 0; const one = 1;
> foo x = case x of one = "one"; zero = "zero"; _ = "???" end;
> show foo
foo x = case x of one = "one"; zero = "zero"; _ = "???" end;
> foo zero, foo one, foo 99;
warning: rule never reduced: zero = "zero";
warning: rule never reduced: _ = "???";
"one","one","one"
.fi
.PP
This is the same kind of pitfall as discussed in the context of the `foop'
predicate in \fIHead = Function\fP above. However, it
.I is
possible to also declare a
.B const
symbol as
.B nullary
(with the usual caveats, see the \fIHead = Function\fP section) and have it
behave like a nullary symbol on the left-hand side of a rule. In that case the
value of the symbol will be substituted for its occurrences in a pattern:
.sp
.nf
> nullary zero one;
> bar x = case x of one = "one"; zero = "zero"; _ = "???" end;
> show bar
bar x = case x of 1 = "one"; 0 = "zero"; _ = "???" end;
> bar zero, bar one, bar 99;
"zero","one","???"
.fi
.SS External C Functions
The interpreter always takes your
.B extern
declarations of C routines at face value. It will not go and read any C header
files to determine whether you actually declared the function correctly! So
you have to be careful to give the proper declarations, otherwise your program
will probably segfault calling the function.
.PP
You also have to be careful when passing generic pointer values to external C
routines, since currently there is no type checking for these; any pointer
type other than char*, expr* and the matrix pointer types is effectively
treated as void*. This considerably simplifies lowlevel programming and
interfacing to C libraries, but also makes it very easy to have your program
segfault all over the place. Therefore it is highly recommended that you wrap
your lowlevel code in Pure routines and data structures which do all the
checks necessary to ensure that only the right kind of data is passed to C
routines.
.PP
Another limitation of the C interface is that it does not offer any special
support for C structs and C function parameters. However, an optional addon
module is available which interfaces to the libffi library to provide that
kind of functionality, please see the description of the
.B pure-ffi
module on the Pure website for details.
.PP
Last but not least, to make it easier to create Pure interfaces to large C
libraries, there's a separate
.B pure-gen
program available at the Pure website. This program takes a C header (.h) file
and creates a corresponding Pure module with definitions and
.B extern
declarations for the constants and functions declared in the header. Please
refer to the
.BR pure-gen (1)
manual page for details.
.SS Special Forms
Special forms are recognized at compile time only. Thus the `catch' function,
as well as `quote' and the operators `&&', `||', `$$' and `&', are only
treated as special forms in direct (saturated) calls. They can still be used
if you pass them around as function values or in partial applications, but in
this case they lose all their special call-by-name argument processing.
.SS Laziness
Pure does lazy evaluation in the same way as Alice ML, providing an explicit
operation (&) to defer evaluation and create a ``future'' which is called by
need. However, note that like any language with a basically eager evaluation
strategy, Pure cannot really support lazy evaluation in a fully automatic
way. That is, coding an operation so that it works with infinite data
structures usually requires additional thought, and sometimes special code
will be needed to recognize futures in the input and handle them
accordingly. This can be hard, but of course in the case of the prelude
operations this work has already been done for you, so as long as you stick to
these, you'll never have to think about these issues. (It should be noted here
that lazy evaluation has its pitfalls even in fully lazy FPLs, such as hidden
memory leaks and other kinds of subtle inefficiencies or non-termination
issues resulting from definitions being too lazy or not lazy enough. You can
read about that in any good textbook on Haskell.)
.PP
The prelude goes to great lengths to implement all standard list operations in
a way that properly deals with streams (a.k.a. list futures).  What this all
boils down to is that all list operations which can reasonably be expected to
operate in a lazy way on streams, will do so. (Exceptions are inherently eager
operations such as `#', reverse and foldl.) Only those portions of an input
stream will be traversed which are strictly required to produce the
result. For most purposes, this works just like in fully lazy FPLs such as
Haskell. However, there are some notable differences:
.IP *
Since Pure uses dynamic typing, some of the list functions may have to peek
ahead one element in input streams to check their arguments for validity,
meaning that these functions will be slightly more eager than their Haskell
counterparts.
.IP *
Pure's list functions never produce truly cyclic list structures such as the
ones you get, e.g., with Haskell's `cycle' operation. (This is actually a good
thing, because the current implementation of the interpreter cannot
garbage-collect cyclic expression data.) Cyclic streams such as `cycle [1]' or
`fix (\ex -> 1:x)' will of course work as expected, but, depending on the
algorithm, memory usage may increase linearly as they are traversed.
.IP *
Pattern matching is always refutable (and therefore eager) in Pure. If you
need something like Haskell's irrefutable matches, you'll have to code them
explicitly using futures. See the definition of the `unzip' function in the
prelude for an example showing how to do this.
.SS Reflection
Pure versions since 0.12 offer some basic reflection capabilities via the
.B evalcmd
primitive. This function provides access to interactive commands like
.BR clear ,
.B save
and
.BR show ,
which enable you to inspect and modify the running program. The only
``canonical'' way to represent an entire Pure program in Pure itself is the
program text, hence
.B evalcmd
only provides a textual interface at this time. But of course custom
higher-level representations can be built on top of that.
.PP
Here's an example showing what can be done using the
.B show
command and a little bit of trivial text processing. The following
.B sym_info
function retrieves information about a given collection of global symbols in a
way which can be processed in a Pure program. The `cat' argument can be any
combination of the letters "c", "v", "f" and "m" denoting the categories of
constants, variables, functions and macros, respectively. (You can also just
leave this empty if you don't care about the type of symbol.) The `pat'
argument is a shell-like glob pattern for the name of symbols which should be
listed (just "*" matches all symbols). The result is a list of tuples (name,
value, cat, descr) with the name of the symbol and its value, as well as the
category and description of the symbol, as provided by \fBshow -s\fP.
.sp
.nf
\fBusing\fP system;
sym_info cat::string pat::string
= [name,eval ("("+name+")"),descr | name,descr = info]
\fBwhen\fP
  // Get the info about matching symbols from the 'show' command.
  info = evalcmd $ sprintf "show -sg%s %s" (cat,pat);
  // Split into lines.
  info = \fBif\fP null info \fBthen\fP [""] \fBelse\fP split "\en" $ init info;
  // Get rid of the last line with the summary information.
  info = init info;
  // Retrieve the information that we need.
  info = [x | x@(s,_) = map fields info;
  // Get rid of extra lines containing extern and fixity declarations.
          s ~= "extern" && s ~= "nullary" &&
          s ~= "prefix" && s ~= "postfix" && ~fnmatch "infix*" s 0];
\fBend\fP \fBwith\fP
  // Regex call to split the summary information about one symbol, as
  // returned by 'show -s', into the name and description parts.
  fields s::string = tuple $
          [info!2 | info = tail $ regs $ reg_info $
           regex "([^ ]+)[ ]+([a-z]*)[ ]*(.*)" REG_EXTENDED s 0];
\fBend\fP;
.fi
.PP
E.g., this call retrieves information about all defined macros:
.sp
.nf
> sym_info "m" "*";
[("$",($),"mac","2 args, 1 rules"),(".",(.),"mac","3 args, 1 rules"),
("quasiquote",quasiquote,"mac","1 args, 4 rules"),
("void",void,"mac","1 args, 3 rules")]
.fi
.SS Stack Size and Tail Recursion
Pure programs may need a considerable amount of stack space to handle
recursive function and macro calls, and the interpreter itself also takes its
toll. So you should configure your system accordingly (8 MB of stack space is
recommended for 32 bit systems, systems with 64 bit pointers probably need
more). If the
.B PURE_STACK
environment variable is defined, the interpreter performs advisory stack
checks and raises a Pure exception if the current stack size exceeds the given
limit. The value of
.B PURE_STACK
should be the maximum stack size in kilobytes. Please note that this is only
an advisory limit which does \fInot\fP change the program's physical stack
size. Your operating system should supply you with a command such as
.BR ulimit (1)
to set the real process stack size. Also note that this feature isn't 100%
foolproof yet, since for performance reasons the stack will be checked only on
certain occasions, such as entry into a global function.
.PP
Fortunately, Pure normally does proper tail calls (if LLVM provides that
feature on the platform at hand), so most tail-recursive definitions should
work fine in limited stack space. For instance, the following little program
will loop forever if your platform supports the required optimizations:
.sp
.nf
loop = loop;
.fi
.PP
This also works if your definition involves function parameters, guards and
multiple equations, of course. Moreover, conditional expressions
(\fBif\fP-\fBthen\fP-\fBelse\fP) are tail-recursive in both branches, and the
sequence operator $$ is tail-recursive in its second operand. Note, however,
that the logical operators && and || are
.I not
tail-recursive in Pure, because they are required to
.I always
yield a proper truth value (0 or 1), which wouldn't be possible with tail call
semantics. (The rationale behind this design decision is that it allows the
compiler to generate much better code for logical expressions.)
.PP
There is one additional restriction in the current implementation, namely that
a tail call will be eliminated \fIonly\fP if the call is done \fIdirectly\fP,
i.e., through an explicit call, not through a (global or local) function
variable. Otherwise the call will be handled by the runtime system which is
written in C and can't do proper tail calls because C can't (at least not in a
portable way). This also affects mutually recursive global function calls,
since there the calls are handled in an indirect way, too, through an
anonymous global variable. (This is done so that a global function definition
can be changed at any time during an interactive session, without having to
recompile the entire program.) However, mutual tail recursion does work with
\fIlocal\fP functions, so it's easy to work around this limitation.
.SS Handling of Asynchronous Signals
As described in section \fIEXCEPTION HANDLING\fP, signals delivered to the
process can be caught and handled with Pure's exception handling
facilities. Like stack checks, checks for pending signals are only performed
at certain places, such as entry into a global function. This doesn't include
tail calls, however, so a busy loop like `loop = loop;' will \fInever\fP be
interrupted. To work around this, just add a call to another global function
to your loop to make it interruptible. For instance:
.sp
.nf
loop = check $$ loop;
check = ();
.fi
.PP
To handle signals while the above loop is executing, you can add an exception
handler like the following:
.sp
.nf
loop = catch handle check $$ loop
\fBwith\fP handle (signal k) = catch handle (...) \fBend\fP;
.fi
.PP
(Note the `catch handle' around the signal processing code which is needed for
safety because another signal may arrive while the signal handler is being
executed.)
.PP
Of course, in a real application the `check' function would most likely have
to do some actual processing, too. In that case you'd probably want the `loop'
function to carry around some ``state'' argument to be processed by the
`check' routine, which then returns an updated state value for the next
iteration. This can be implemented as follows:
.sp
.nf
loop x = loop (catch handle (check x))
\fBwith\fP handle (signal k) = catch handle (...) \fBend\fP;
check x = ...;
.fi
.SH FILES
.TP
.B ~/.pure_history
Interactive command history.
.TP
\fB~/.purerc\fP, \fB.purerc\fP, \fB.pure\fP
Interactive startup files. The latter is usually a dump from a previous
interactive session.
.TP
.B prelude.pure
Standard prelude. If available, this script is loaded before any other
definitions, unless
.B -n
was specified.
.SH ENVIRONMENT
.TP
.B PURELIB
Directory to search for library scripts, including the prelude. If
.B PURELIB
is not set, it defaults to some default location specified at installation
time.
.TP
.B PURE_INCLUDE
Additional directories (in colon-separated format) to be searched for included
scripts.
.TP
.B PURE_LIBRARY
Additional directories (in colon-separated format) to be searched for dynamic
libraries.
.TP
.B PURE_MORE
Shell command to be used for paging through output of the
.B show
command, when the interpreter runs in interactive mode.
.TP
.B PURE_PS
Command prompt used in the interactive command loop (">\ " by default).
.TP
.B PURE_STACK
Maximum stack size in kilobytes (default: 0 = unlimited).
.SH LICENSE
GPL V3 or later. See the accompanying COPYING file for details.
.SH AUTHOR
Albert Graef <Dr.Graef@t-online.de>, Dept. of Computer Music, Johannes
Gutenberg University of Mainz, Germany.
.SH SEE ALSO
(All software listed here is freely available, usually under the GNU Public
License.)
.TP
.B Aardappel
Another functional programming language based on term rewriting,
\fIhttp://wouter.fov120.com/aardappel\fP.
.TP
.B Alice ML
A version of ML (see below) from which Pure borrows its model of lazy
evaluation, \fIhttp://www.ps.uni-sb.de/alice\fP.
.TP
.B GNU Octave
A popular high-level language for numeric applications and free MATLAB
replacement, \fIhttp://www.gnu.org/software/octave\fP.
.TP
.B GNU Scientific Library
A free software library for numeric applications, required for Pure's
numeric matrix support, \fIhttp://www.gnu.org/software/gsl\fP.
.TP
.B Haskell
A popular non-strict FPL, \fIhttp://www.haskell.org\fP.
.TP
.B LLVM
The LLVM code generator framework, \fIhttp://llvm.org\fP.
.TP
.B ML
A popular strict FPL. See Robin Milner, Mads Tofte, Robert Harper,
D. MacQueen: \fIThe Definition of Standard ML (Revised)\fP. MIT Press, 1997.
.TP
.B Pure
Find the latest releases and the mailing list at the Pure website,
\fIhttp://pure-lang.googlecode.com\fP.
.TP
.B Q
Another term rewriting language by yours truly, \fIhttp://q-lang.sf.net\fP.
